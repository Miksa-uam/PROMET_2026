{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper 1 - eating behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the relevant directories used in this paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is pulled from the standardized data folder; subsequently, it is stored and managed in the paper 1 folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the source and output directories\n",
    "source_directory = r\"C:\\Users\\Felhasználó\\Desktop\\Projects\\PNK_DB2\\DB2_standard\"\n",
    "paper1_directory = r\"C:\\Users\\Felhasználó\\Desktop\\Projects\\PNK_DB2\\paper1_emotional\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(paper1_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a research question-specific SQL database subset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check those medical records where any/3+/all emotional values are available, and filter the database to contain only the specified patients and medical records. Save the data to 3 new SQL files - one with any, one with some, one with all values available. For research purposes, the last one is most likely to be used. The first two may be relevant if trying to increase the sample size for one or a few specific emotional values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any emotional data points are available in 2482 records from 2437 patients\n",
      "At least 3 emotional data points are available in 2169 records from 2132 patients\n",
      "All emotional data points are available in 1853 records from 1826 patients\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Use the above defined directories\n",
    "db_path = os.path.join(source_directory, \"pnk_db2_colclean.sqlite\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# List all tables in the database\n",
    "query_tables = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(query_tables, conn)\n",
    "table_names = tables['name'].tolist()\n",
    "\n",
    "# Define criteria for filtering for any/3+/all emotional values available\n",
    "def create_filtered_database(criteria, output_filename):\n",
    "    # Set up the appropriate query based on the criteria for the three scenarios\n",
    "    if criteria == \"any\":\n",
    "        # to select records where at least one emotional variable is not null\n",
    "        query = \"\"\"\n",
    "        SELECT medical_record_id, patient_id\n",
    "        FROM medical_records_colclean\n",
    "        WHERE hunger IS NOT NULL\n",
    "           OR satiety IS NOT NULL\n",
    "           OR emotional_eating IS NOT NULL\n",
    "           OR emotional_eating_value IS NOT NULL\n",
    "           OR quantity_control IS NOT NULL\n",
    "           OR impulse_control IS NOT NULL;\n",
    "        \"\"\"\n",
    "    elif criteria == \"3plus\":\n",
    "        # to select records where at least three emotional variables are not null\n",
    "        query = \"\"\"\n",
    "        SELECT medical_record_id, patient_id\n",
    "        FROM medical_records_colclean\n",
    "        WHERE (CASE WHEN hunger IS NOT NULL THEN 1 ELSE 0 END +\n",
    "               CASE WHEN satiety IS NOT NULL THEN 1 ELSE 0 END +\n",
    "               CASE WHEN emotional_eating IS NOT NULL THEN 1 ELSE 0 END +\n",
    "               CASE WHEN emotional_eating_value IS NOT NULL THEN 1 ELSE 0 END +\n",
    "               CASE WHEN quantity_control IS NOT NULL THEN 1 ELSE 0 END +\n",
    "               CASE WHEN impulse_control IS NOT NULL THEN 1 ELSE 0 END) >= 3;\n",
    "        \"\"\"\n",
    "    elif criteria == \"all\":\n",
    "        # to select records where all emotional variables are not null \n",
    "        query = \"\"\"\n",
    "        SELECT medical_record_id, patient_id\n",
    "        FROM medical_records_colclean\n",
    "        WHERE hunger IS NOT NULL\n",
    "          AND satiety IS NOT NULL\n",
    "          AND emotional_eating IS NOT NULL\n",
    "          AND emotional_eating_value IS NOT NULL\n",
    "          AND quantity_control IS NOT NULL\n",
    "          AND impulse_control IS NOT NULL;\n",
    "        \"\"\"\n",
    "    \n",
    "    # Get the relevant records, and extract their medical record and patient IDs\n",
    "    relevant_records = pd.read_sql_query(query, conn)\n",
    "    relevant_medical_record_ids = tuple(relevant_records['medical_record_id'])\n",
    "    relevant_patient_ids = tuple(relevant_records['patient_id'])\n",
    "    \n",
    "    # Create a new database in the output directory\n",
    "    output_db_path = os.path.join(paper1_directory, output_filename)\n",
    "    filtered_conn = sqlite3.connect(output_db_path)\n",
    "    \n",
    "    # Filter each table in the source SQl to only contain the records that comply the criteria of the given scenario; \n",
    "    # ie. they have records where any/3+/all emotional variables are available\n",
    "    for table_name in table_names:\n",
    "        if table_name.startswith(\"sqlite_\"):\n",
    "            # Skip any SQLite system tables\n",
    "            continue \n",
    "        # In case of tables that may contain several medical records from the same patient, \n",
    "        # filter by medical_record_id\n",
    "        if table_name == \"medical_records_colclean\" or table_name == \"prescriptions_colclean\":\n",
    "            query = f\"\"\"\n",
    "            SELECT * \n",
    "            FROM {table_name}\n",
    "            WHERE medical_record_id IN {relevant_medical_record_ids}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # For all other tables, filter by patient_id only, as medical record ID is not available in those\n",
    "            query_check_column = f\"PRAGMA table_info({table_name});\"\n",
    "            columns = pd.read_sql_query(query_check_column, conn)\n",
    "            if 'patient_id' not in columns['name'].values:\n",
    "                continue  # Skip tables without patient_id\n",
    "            query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM {table_name}\n",
    "            WHERE patient_id IN {relevant_patient_ids}\n",
    "            \"\"\"\n",
    "        \n",
    "        # Execute the given query and save the result in a new SQLite database\n",
    "        filtered_data = pd.read_sql_query(query, conn)\n",
    "        filtered_data.to_sql(table_name, filtered_conn, index=False, if_exists=\"replace\")\n",
    "    \n",
    "    filtered_conn.close()\n",
    "    return len(relevant_records), len(set(relevant_records['patient_id']))\n",
    "\n",
    "# Create and save the three databases for the three scenarios - any/3+/all emotional variables available\n",
    "any_count, any_patients = create_filtered_database(\"any\", \"emotional_any_notna.sqlite\")\n",
    "three_plus_count, three_plus_patients = create_filtered_database(\"3plus\", \"emotional_3plus_notna.sqlite\")\n",
    "all_count, all_patients = create_filtered_database(\"all\", \"emotional_all_notna.sqlite\")\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Print summary\n",
    "print(f\"Any emotional data points are available in {any_count} records from {any_patients} patients\")\n",
    "print(f\"At least 3 emotional data points are available in {three_plus_count} records from {three_plus_patients} patients\")\n",
    "print(f\"All emotional data points are available in {all_count} records from {all_patients} patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and link measurements to prescriptions and medical records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the patient ID and the date of a given measurements, look for prescriptions with the same patient ID that cover the range of time in which the measurement was taken. This way, measurements can be linked to important metadata, such as the prescription and medical record they belong to, the step of the programme they were taken in, etc. \n",
    "\n",
    "In summary, this is a key step in the research, without which data on any measurement's identity would be insufficient, and measurements from different prescriptions of the same individual could be mixed, for example. In a previous attempt, I tried identifying blocks of measurements as those that are taken within two months of each other, but I consider this a much more solid approach. \n",
    "\n",
    "It is important to note that some patients may take repeated measurements on the same occasion. These duplicates need to be removed, as they inflate the dataset. \n",
    "\n",
    "After removing the duplicates, measurements and prescriptions are linked in a two-step process. \n",
    "\n",
    "First, measurements are linked to all possible prescriptions that can belong to them based on the shared patient ID (this scenario where every option is linked to every option is called a Cartesian product). \n",
    "\n",
    "After, these possible links are filtered by date: a measurement belongs to a prescription if it is within its validity period, or is 5 days within its start or end dates. In the latter case, a measurement may be assigned to multiple prescriptions; if this happens, it is assigned to the one it is closer to in time. \n",
    "\n",
    "If a measurement is not succesfully linked to any prescription, it is lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate measurements removed. There are 35709 measurements from 1826 patients.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Remove duplicate measurements before doing any data frame merging. \n",
    "Any measurement from the same patient on the same day (ignoring time) with the same weight should be considered a duplicate.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Connect to the database, load the measurements table\n",
    "conn = sqlite3.connect(os.path.join(paper1_directory, \"emotional_all_notna.sqlite\"))\n",
    "measurements = pd.read_sql_query(\"SELECT * FROM measurements_colclean\", conn)\n",
    "\n",
    "# Convert measurement_date to datetime, if not already in that format. \n",
    "# Add a temporary column with the measurement date only; time is ignored, \n",
    "# as repeated measurements are at least a few seconds or minutes apart. \n",
    "measurements['measurement_date'] = pd.to_datetime(measurements['measurement_date'])\n",
    "measurements['measurement_date_date'] = measurements['measurement_date'].dt.date\n",
    "# After, remove duplicates based on patient id, date, and weight. \n",
    "# Drop the temporary column. \n",
    "measurements_rowclean = measurements.drop_duplicates(subset=['patient_id', 'measurement_date_date', 'weight_kg'])\n",
    "measurements_rowclean = measurements_rowclean.drop(columns=['measurement_date_date'])\n",
    "# Save the cleaned measurements back to the database with the _rowclean name code\n",
    "measurements_rowclean.to_sql(\"measurements_rowclean\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(f\"Duplicate measurements removed. There are {len(measurements_rowclean)} measurements from {measurements_rowclean['patient_id'].nunique()} patients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements are linked to their corresponding prescriptions and medical records. \n",
      "There are a total of 20976 measurements from 1678 medical records of 1664 patients.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Link metadata from the prescriptions table to measurements. \n",
    "\n",
    "The two dataframes are merged based on patient_id, creating a Cartesian product of the two tables, \n",
    "where every measurement from one patient is linked to every possible prescription from that patient.\n",
    "\n",
    "This Cartesian product is then filtered based on the dates of both the measurement and the prescription, \n",
    "in order to, preferably, only consider a prescription being linked to a given measurement\n",
    "if the measurement date is between the prescription's start and end dates. \n",
    "\n",
    "If a measurement is not within any prescription's validity period, \n",
    "there is a permissivity of 5 days, meaning that a measurement can be linked to a prescription if\n",
    "it is within 5 days from the start or end date of the prescription.\n",
    "If this allows a measurement to be linked to multiple prescriptions,\n",
    "it is linked to the one it is closest to in date. \n",
    "\n",
    "If a measurement is not linked to any valid prescription, \n",
    "it is excluded from the outuput. \n",
    "\"\"\"\n",
    "\n",
    "# Connect to the paper-specific database, load the prescriptions table, and make sure its date values are in datetime format\n",
    "conn = sqlite3.connect(os.path.join(paper1_directory, \"emotional_all_notna.sqlite\"))\n",
    "prescriptions = pd.read_sql_query(\"SELECT * FROM prescriptions_colclean\", conn)\n",
    "prescriptions['prescription_creation_date'] = pd.to_datetime(prescriptions['prescription_creation_date'])\n",
    "prescriptions['prescription_validity_end_date'] = pd.to_datetime(prescriptions['prescription_validity_end_date'])\n",
    "\n",
    "# Merge the measurements and prescriptions data frames on patient ID,\n",
    "# creating the Cartesian product that needs further date-based filtering\n",
    "merged = pd.merge(measurements_rowclean, prescriptions, on=\"patient_id\", how=\"left\", suffixes=('_meas', '_presc'))\n",
    "\n",
    "# To execute date-based filtering: \n",
    "# First, define those measurements that are within the range of a prescription. \n",
    "# If any measurement can be assigned to a prescription based on this criteria, it will be. \n",
    "merged['measurement_in_prescription_range'] = (\n",
    "    (merged['measurement_date'] >= merged['prescription_creation_date']) &\n",
    "    (merged['measurement_date'] <= merged['prescription_validity_end_date'])\n",
    ")\n",
    "# If after this, a measurement is still not linked to any prescription due to not being in the range of any, \n",
    "# it will be linked to the prescription it is closest to, within a 5-day permissivity range. \n",
    "# For these out-of-range measurements, first, the distance from the start/end dates of any prescription is calculated. \n",
    "merged['days_before_prescription_start'] = (merged['prescription_creation_date'] - merged['measurement_date']).dt.days\n",
    "merged['days_after_prescription_end'] = (merged['measurement_date'] - merged['prescription_validity_end_date']).dt.days\n",
    "# After, near-range measurements are defined, \n",
    "# as measurements that are NOT within the range of any prescription, \n",
    "# AND they are at within 5 days before the start/after the end of any prescription. \n",
    "merged['measurement_near_prescription_range'] = (\n",
    "    (~merged['measurement_in_prescription_range']) &\n",
    "    (\n",
    "        ((merged['days_before_prescription_start'] <= 5) & (merged['days_before_prescription_start'] > 0)) |\n",
    "        ((merged['days_after_prescription_end'] <= 5) & (merged['days_after_prescription_end'] > 0))\n",
    "    )\n",
    ")\n",
    "# After, a distance metric calculation determines how far a given measurement is from a prescription. \n",
    "# In-range measurements get a distance metric of 0,\n",
    "# while out-of-range measurements get the minimum distance to any boundary they are close to. \n",
    "merged['measurement_distance_from_prescription_range'] = merged.apply(\n",
    "    lambda row: 0 if row['measurement_in_prescription_range'] else min(max(row['days_before_prescription_start'], 0), max(row['days_after_prescription_end'], 0)),\n",
    "    axis=1\n",
    ")\n",
    "# After defining the in-range and near-range logics, the database (currently containing Cartesian products) \n",
    "# is filtered to keep only in-or near-range measurements. \n",
    "# Any measurements not assigned to a prescription is lost. \n",
    "measurements_with_metadata = merged[merged['measurement_in_prescription_range'] | merged['measurement_near_prescription_range']].copy()\n",
    "# In edge cases where multiple prescriptions are linked to a single measurement, only the closest match is kept. \n",
    "# This is done by sorting the data frame by patient id, measurement date and distance from range, \n",
    "# and if multiple measurement-prescription pairs from the same patient on the same date are found, \n",
    "# duplicates are removed and only the row with the smallest distance from range is kept. \n",
    "measurements_with_metadata = measurements_with_metadata.sort_values(['patient_id', 'measurement_date', 'measurement_distance_from_prescription_range'])\n",
    "measurements_with_metadata = measurements_with_metadata.drop_duplicates(['patient_id', 'measurement_date'])\n",
    "\n",
    "# After filtering the data frame, columns are reordered, and any irrelevant ones, like prescribed supplements, are dropped. \n",
    "column_order = [\n",
    "    'patient_id',\n",
    "    'medical_record_id',\n",
    "    'prescription_id',\n",
    "    'measurement_date',\n",
    "    'prescription_creation_date',\n",
    "    'prescription_validity_end_date',\n",
    "    'prescription_validity_days',\n",
    "    'method',\n",
    "    'step',\n",
    "    'weight_kg',\n",
    "    'bmi',\n",
    "    'bmr_kcal',\n",
    "    'fat_%',\n",
    "    'vat_%',\n",
    "    'muscle_%',\n",
    "    'water_%',\n",
    "    'measurement_in_prescription_range',\n",
    "    'days_before_prescription_start',\n",
    "    'days_after_prescription_end',\n",
    "    'measurement_near_prescription_range',\n",
    "    'measurement_distance_from_prescription_range'\n",
    "]\n",
    "measurements_with_metadata = measurements_with_metadata[column_order]\n",
    "\n",
    "# The measurements_with_metadata data frame is saved within the SQL database, and some summary info is printed. \n",
    "measurements_with_metadata.to_sql(\"measurements_with_metadata\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(f\"Measurements are linked to their corresponding prescriptions and medical records. \\n\"\n",
    "    f\"There are a total of {measurements_with_metadata.shape[0]} measurements \"\n",
    "    f\"from {measurements_with_metadata['medical_record_id'].nunique()} medical records \"\n",
    "    f\"of {measurements_with_metadata['patient_id'].nunique()} patients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add sex and baseline/final weight data to medical records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an effort to create data frames containing the most possible information in one place, the medical records data frame is completed with the sex (originally stored in Patients) as well as the baseline and final weight data (measurements linked to medical records stored in measurements_with_metadata) of patients. \n",
    "\n",
    "Besides executing these merge operations, the code checks the time passed between baseline and final measurements in each medical record, along with whether the measurements are close to the beginning/end date of the medical record they belong to or not. This helps checking whether the length of the actual followup is similar to that of the medical record or not. \n",
    "\n",
    "Any medical record that has no associated measurements is lost here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical records table completed with sex and baseline/final weight data. \n",
      "There are 1678 records available from 1664 patients.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete Medical records by adding sex and baseline/final weight data to it. \n",
    "\n",
    "Sex is fetched from the Patients table, based on the patient_id.\n",
    "\n",
    "Baseline and final weight measurements are obtained from the measurements_with_metadata table created in the previous step. \n",
    "The logic is the following: \n",
    "Measurements are grouped by patient and medical record ID, and the first and last measurements of each group are assigned\n",
    "to the medical records table as baseline and final measurements, respectively.\n",
    "Delta weight is calculated as the difference between final and baseline weights, to obtain negative results. \n",
    "\n",
    "Measurement dates are added and it is checked if they are within the medical record creation and closing dates.\n",
    "\n",
    "If a medical record has no measurements linked to it, it is dropped. \n",
    "\n",
    "Additionally, the 'days_between_measurements' column is added to calculate the number of days between the baseline and final measurements.\n",
    "\n",
    "Finally, the columns are reordered to match the desired order.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the database, load relevant tables\n",
    "conn = sqlite3.connect(os.path.join(paper1_directory, \"emotional_all_notna.sqlite\"))\n",
    "medical_records = pd.read_sql_query(\"SELECT * FROM medical_records_colclean\", conn)\n",
    "patients = pd.read_sql_query(\"SELECT * FROM patients_colclean\", conn)\n",
    "measurements_with_metadata = pd.read_sql_query(\"SELECT * FROM measurements_with_metadata\", conn)\n",
    "\n",
    "# The following functions complete the original medical records data frame with research-relevant variables.\n",
    "# First, add the sex variable to medical_records_complete by merging patients' sex into medical_records_complete based on patient_id\n",
    "\"\"\"\n",
    "Adding sex data to medical records\n",
    "\"\"\"\n",
    "medical_records_complete = pd.merge(\n",
    "    medical_records,\n",
    "    patients[['patient_id', 'sex']],\n",
    "    on='patient_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# After, add baseline and final measurements to medical_records_complete\n",
    "# Treat measurements coming from a given medical record as units\n",
    "# by grouping measurements_with_metadata by patient_id and medical_record_id \n",
    "\"\"\"\n",
    "Adding weight data to medical records\n",
    "\"\"\"\n",
    "grouped_measurements = measurements_with_metadata.groupby(['patient_id', 'medical_record_id'])\n",
    "# Extract the first (baseline) and last (final) measurement for each group\n",
    "baseline = grouped_measurements.first().reset_index()\n",
    "final = grouped_measurements.last().reset_index()\n",
    "# Insert baseline and final measurements into medical_records_complete\n",
    "medical_records_complete = pd.merge(\n",
    "    medical_records_complete,\n",
    "    baseline[['patient_id', 'medical_record_id', 'measurement_date', 'weight_kg', 'bmi']],\n",
    "    on=['patient_id', 'medical_record_id'],\n",
    "    how='left'\n",
    ")\n",
    "medical_records_complete = pd.merge(\n",
    "    medical_records_complete,\n",
    "    final[['patient_id', 'medical_record_id', 'measurement_date', 'weight_kg', 'bmi']],\n",
    "    on=['patient_id', 'medical_record_id'],\n",
    "    how='left',\n",
    "    suffixes=('_baseline', '_final')\n",
    ")\n",
    "# Make sure all dates are in datetime format for further operations, \n",
    "# and calculate delta weight and delta BMI values (final - baseline, so the resulting weight loss value is negative)\n",
    "medical_records_complete['medical_record_creation_date'] = pd.to_datetime(medical_records_complete['medical_record_creation_date'])\n",
    "medical_records_complete['medical_record_closing_date'] = pd.to_datetime(medical_records_complete['medical_record_closing_date'])\n",
    "medical_records_complete['measurement_date_baseline'] = pd.to_datetime(medical_records_complete['measurement_date_baseline'])\n",
    "medical_records_complete['measurement_date_final'] = pd.to_datetime(medical_records_complete['measurement_date_final'])\n",
    "medical_records_complete['delta_weight_kg'] = medical_records_complete['weight_kg_final'] - medical_records_complete['weight_kg_baseline']\n",
    "medical_records_complete['delta_bmi'] = medical_records_complete['bmi_final'] - medical_records_complete['bmi_baseline']\n",
    "# Check if the baseline and final measurements are close to the starting/closing date of the medical record they belong to or not (within a 10-day window). \n",
    "# In some cases, the first measurement is recorded weeks after opening the medical record, or the last one is taken long before closing it. \n",
    "# In other cases, the medical record's closing date is absent, if this happens, the last measurement will be considered as out of range. \n",
    "# This is supposed to help identify cases where the followup has some imperfections. \n",
    "window_days = 10\n",
    "medical_records_complete['baseline_measurement_inrange'] = (\n",
    "    (medical_records_complete['measurement_date_baseline'] >= \n",
    "     medical_records_complete['medical_record_creation_date'] - pd.Timedelta(days=window_days)) &\n",
    "    (medical_records_complete['measurement_date_baseline'] <=\n",
    "     medical_records_complete['measurement_date_baseline'] + pd.Timedelta(days=window_days))\n",
    ")\n",
    "medical_records_complete['final_measurement_inrange'] = (\n",
    "    (medical_records_complete['measurement_date_final'] >= \n",
    "     medical_records_complete['medical_record_closing_date'] - pd.Timedelta(days=window_days)) &\n",
    "    (medical_records_complete['measurement_date_final'] <= \n",
    "     medical_records_complete['medical_record_closing_date'] + pd.Timedelta(days=window_days))\n",
    ")\n",
    "# Add a column that calculates the days passed between baseline and final measurements\n",
    "# This also helps identify cases where the medical record's duration and the actual followup time are very different\n",
    "medical_records_complete['days_between_measurements'] = (\n",
    "    (medical_records_complete['measurement_date_final'] - medical_records_complete['measurement_date_baseline']).dt.days\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Removing medical records with no associated measurements\n",
    "\"\"\"\n",
    "# As for some reason (unidentified as of 16Apr25) many medical records have no available measurements associated to them, \n",
    "# any such instances are dropped from the data frame. \n",
    "medical_records_complete = medical_records_complete.dropna(subset=['weight_kg_baseline', 'weight_kg_final'])\n",
    "\n",
    "\"\"\"\n",
    "Presenting and saving the output\n",
    "\"\"\"\n",
    "# Rename and reorder columns for better clarity and interpretability\n",
    "medical_records_complete = medical_records_complete.rename(columns={\n",
    "    'measurement_date_baseline': 'baseline_measurement_date',\n",
    "    'measurement_date_final': 'final_measurement_date',\n",
    "    'weight_kg_baseline': 'baseline_weight_kg',\n",
    "    'weight_kg_final': 'final_weight_kg', \n",
    "    'bmi_baseline': 'baseline_bmi',\n",
    "    'bmi_final': 'final_bmi'\n",
    "})\n",
    "desired_column_order = [\n",
    "    'patient_id',\n",
    "    'medical_record_id',\n",
    "    'medical_record_creation_date',\n",
    "    'medical_record_closing_date',\n",
    "    'intervention_duration_days',\n",
    "    'baseline_measurement_date',\n",
    "    'final_measurement_date',\n",
    "    'days_between_measurements',\n",
    "    'baseline_measurement_inrange',\n",
    "    'final_measurement_inrange',\n",
    "    'birth_date',\n",
    "    'age',\n",
    "    'age_when_creating_record',\n",
    "    'sex',\n",
    "    'height_m',\n",
    "    'baseline_weight_kg',\n",
    "    'final_weight_kg',\n",
    "    'delta_weight_kg',\n",
    "    'baseline_bmi',\n",
    "    'final_bmi',\n",
    "    'delta_bmi',\n",
    "    'wc_cm_confirm_time',\n",
    "    'pnk_method',\n",
    "    'orders_in_medical_record',\n",
    "    'dietitian_visits',\n",
    "    'physical_activity',\n",
    "    'physical_activity_frequency',\n",
    "    'physical_inactivity_cause',\n",
    "    'weight_gain_cause',\n",
    "    'smoking',\n",
    "    'medications',\n",
    "    'hunger',\n",
    "    'satiety',\n",
    "    'emotional_eating',\n",
    "    'emotional_eating_value',\n",
    "    'quantity_control',\n",
    "    'impulse_control'\n",
    "]\n",
    "medical_records_complete = medical_records_complete[desired_column_order]\n",
    "# Save the complete medical records to the SQL database, and print a summary statement\n",
    "medical_records_complete.to_sql(\"medical_records_complete\", conn, if_exists=\"replace\", index=False)\n",
    "print(f\"Medical records table completed with sex and baseline/final weight data. \\n\" \n",
    "      f\"There are {len(medical_records_complete)} records available from {medical_records_complete['patient_id'].nunique()} patients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the base input for survival analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, data frames specifically prepared for survival analysis are created. Time-to-event (days) of achieving 3 different weight loss targets (5-10-15%) in 3 different time frames (40-60-80 days) is analyzed. Relevant demographic, anthropometric and eating behavior variables are added to each analyzed medical record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting Survival Analysis Script ==========\n",
      "Connecting to input database: C:\\Users\\Felhasználó\\Desktop\\Projects\\PNK_DB2\\paper1_emotional\\emotional_all_notna.sqlite\n",
      "Connecting to output database: C:\\Users\\Felhasználó\\Desktop\\Projects\\PNK_DB2\\paper1_emotional\\survival_analysis.sqlite\n",
      "--- Processing: sa_40d_5p ---\n",
      "--- Processing: sa_40d_10p ---\n",
      "--- Processing: sa_40d_15p ---\n",
      "--- Processing: sa_60d_5p ---\n",
      "--- Processing: sa_60d_10p ---\n",
      "--- Processing: sa_60d_15p ---\n",
      "--- Processing: sa_80d_5p ---\n",
      "--- Processing: sa_80d_10p ---\n",
      "--- Processing: sa_80d_15p ---\n",
      "--- Saving results to output database: C:\\Users\\Felhasználó\\Desktop\\Projects\\PNK_DB2\\paper1_emotional\\survival_analysis.sqlite ---\n",
      "Saving table: sa_40d_5p (1664 rows)\n",
      "Saving table: sa_40d_10p (1664 rows)\n",
      "Saving table: sa_40d_15p (1664 rows)\n",
      "Saving table: sa_60d_5p (1664 rows)\n",
      "Saving table: sa_60d_10p (1664 rows)\n",
      "Saving table: sa_60d_15p (1664 rows)\n",
      "Saving table: sa_80d_5p (1664 rows)\n",
      "Saving table: sa_80d_10p (1664 rows)\n",
      "Saving table: sa_80d_15p (1664 rows)\n",
      "Saving summary table: survival_analysis_summary (9 rows)\n",
      "--- All results saved successfully ---\n",
      "\n",
      "--- Survival Analysis Summary ---\n",
      "  analysis_name  weight_loss_target  time_window  total_patients  achieved_target  dropout_count  avg_weight_loss_pct\n",
      "0     sa_40d_5p                   5           40            1664              987            584             4.211154\n",
      "1    sa_40d_10p                  10           40            1664              328            784             5.682572\n",
      "2    sa_40d_15p                  15           40            1664               24            789             5.747578\n",
      "3     sa_60d_5p                   5           60            1664             1019            611             4.272037\n",
      "4    sa_60d_10p                  10           60            1664              452            989             6.097951\n",
      "5    sa_60d_15p                  15           60            1664               83           1069             6.539477\n",
      "6     sa_80d_5p                   5           80            1664             1027            625             4.289597\n",
      "7    sa_80d_10p                  10           80            1664              506           1061             6.214567\n",
      "8    sa_80d_15p                  15           80            1664              138           1226             6.895883\n",
      "--- End Summary ---\n",
      "Analysis data successfully generated and saved to C:\\Users\\Felhasználó\\Desktop\\Projects\\PNK_DB2\\paper1_emotional\\survival_analysis.sqlite\n",
      "Closing database connections...\n",
      "========== Survival Analysis Script Finished ==========\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "from datetime import timedelta\n",
    "# Removed: import logging\n",
    "\n",
    "\"\"\"\n",
    "CONFIGURATION\n",
    "\"\"\"\n",
    "# Define directories and database paths - paper1_directory should be defined \n",
    "# in the first cell of this notebook chapter\n",
    "input_db_path = os.path.join(paper1_directory, 'emotional_all_notna.sqlite')\n",
    "input_measurements = \"measurements_with_metadata\"\n",
    "input_medical_records = \"medical_records_complete\"\n",
    "output_db_path = os.path.join(paper1_directory, 'survival_analysis.sqlite')\n",
    "\n",
    "# Define analysis parameters\n",
    "weight_loss_targets = [5, 10, 15]     # Weight loss target percentages\n",
    "time_windows = [40, 60, 80]       # Time windows (centers) in days\n",
    "window_span = 10                   # Permissible span around windows (+/- days)\n",
    "\n",
    "# Define the variables stored in medical_records_complete that are relevant for the analysis. \n",
    "# These include basic metadata like patient and record ID,\n",
    "# basic factors such as age and sex, \n",
    "# as well as the emotional and eating behavior variables pivotal to the research question. \n",
    "# The list can be amended on demand - \n",
    "# for example, right now it does not include medical record creating and closing dates. \n",
    "relevant_medical_values = ['patient_id', 'medical_record_id', 'sex', 'age',\n",
    "                             'height_m', 'baseline_bmi', 'hunger', 'satiety', 'emotional_eating',\n",
    "                             'emotional_eating_value', 'quantity_control', 'impulse_control']\n",
    "\n",
    "\"\"\"\n",
    "DATA LOADING & PREPARATION\n",
    "\"\"\"\n",
    "\n",
    "def load_measurements(connection):\n",
    "    \"\"\"\n",
    "    Load measurements from the measurement_with_metadata table; \n",
    "    make sure key values are in the correct format. \n",
    "    \"\"\"\n",
    "    query = f\"SELECT * FROM {input_measurements}\"\n",
    "    measurements = pd.read_sql_query(query, connection)\n",
    "    measurements['measurement_date'] = pd.to_datetime(measurements['measurement_date'], errors='coerce')\n",
    "    measurements['weight_kg'] = pd.to_numeric(measurements['weight_kg'], errors='coerce')\n",
    "    return measurements\n",
    "\n",
    "def load_medical_records(connection):\n",
    "    \"\"\"\n",
    "    Load medical records from the medical_records_complete table;\n",
    "    make sure date values are in datetime format. \n",
    "    The exact columns to be used are defined in the prepare_patient_data function.\n",
    "    \"\"\"\n",
    "    query = f\"SELECT * FROM {input_medical_records}\"\n",
    "    medical_records = pd.read_sql_query(query, connection)\n",
    "    medical_records['medical_record_creation_date'] = pd.to_datetime(medical_records['medical_record_creation_date'], errors='coerce')\n",
    "    return medical_records\n",
    "\n",
    "def prepare_patient_data(measurements, medical_records):\n",
    "    \"\"\"\n",
    "    Filter measurements to only include those from the earliest medical record for each patient.\n",
    "    Merge measurements with relevant medical record data, including the pivotal eating behavior scores. \n",
    "    \"\"\"\n",
    "    # Filter measurements to only include those from the first treatment record of each patient\n",
    "    earliest_records_with_data = measurements.sort_values('measurement_date')\\\n",
    "        .groupby('patient_id')['medical_record_id']\\\n",
    "        .first()\\\n",
    "        .reset_index()\n",
    "    filtered_measurements = pd.merge(\n",
    "        measurements,\n",
    "        earliest_records_with_data,\n",
    "        on=['patient_id', 'medical_record_id'],\n",
    "        how='inner'\n",
    "    )\n",
    "    # Identify the baseline measurement in each record\n",
    "    baseline_data = filtered_measurements.sort_values('measurement_date')\\\n",
    "                                       .groupby(['patient_id', 'medical_record_id'])\\\n",
    "                                       .first()\\\n",
    "                                       .reset_index()\n",
    "\n",
    "    cols_to_select = [col for col in relevant_medical_values if col in medical_records.columns]\n",
    "    medical_record_data = medical_records[cols_to_select]\n",
    "    # Merge baseline measurements with relevant medical record data\n",
    "    prepared_data = pd.merge(\n",
    "        baseline_data,\n",
    "        medical_record_data,\n",
    "        on=['patient_id', 'medical_record_id'],\n",
    "        how='left' # Keep all baseline data\n",
    "    )\n",
    "    return prepared_data, filtered_measurements\n",
    "\n",
    "\"\"\"\n",
    "CALCULATE WEIGHT LOSS OUTCOMES\n",
    "\"\"\"\n",
    "\n",
    "def _get_patient_baseline(patient_data, patient_id, medical_record_id):\n",
    "    \"\"\"\n",
    "    Get the baseline data for each patient's corresponding medical record.\n",
    "    \"\"\"\n",
    "    patient_baseline = patient_data[\n",
    "        (patient_data['patient_id'] == patient_id) &\n",
    "        (patient_data['medical_record_id'] == medical_record_id)\n",
    "    ]\n",
    "    if len(patient_baseline) == 0:\n",
    "        print(f\"WARN: No baseline data found for patient {patient_id}, record {medical_record_id}. Skipping.\")\n",
    "        return None\n",
    "    return patient_baseline.iloc[0]\n",
    "\n",
    "def _check_target_achievement(measurements_within_window, baseline_weight, weight_loss_target):\n",
    "    \"\"\"\n",
    "    Check if the weight loss target was achieved in some of the given measurements.\n",
    "    \"\"\"\n",
    "    # Set default to False/None\n",
    "    target_achieved = False\n",
    "    first_success_measurement = None\n",
    "    # Calculate weight loss percentage for each measurement in the window, \n",
    "    # and check if it meets the target\n",
    "    for _, row in measurements_within_window.iterrows():\n",
    "        current_weight = row['weight_kg']\n",
    "        if baseline_weight is not None and baseline_weight > 0:\n",
    "            current_weight_loss = ((baseline_weight - current_weight) / baseline_weight) * 100\n",
    "            if round(current_weight_loss, 2) >= weight_loss_target:\n",
    "                target_achieved = True\n",
    "                first_success_measurement = row\n",
    "                break # Stop at the first success; if that is not identified, target_achieved remains False as by default\n",
    "    return target_achieved, first_success_measurement\n",
    "\n",
    "def _determine_final_measurement(target_achieved, first_success_row, measurements_around_cutoff,\n",
    "                                measurements_within_window, baseline_date, window_center):\n",
    "    \"\"\"\n",
    "    Determine the final measurement based on success or censoring (ie. completion without success) rules.\n",
    "    \"\"\"\n",
    "    # Set final measurement to None by default\n",
    "    final_measurement = None\n",
    "    # Set target final date based on the given time window\n",
    "    target_date = baseline_date + timedelta(days=window_center)\n",
    "    # If weight loss target was achieved at any point of the followup time window,\n",
    "    # use the first success measurement as the final measurement.  \n",
    "    if target_achieved:\n",
    "        final_measurement = first_success_row\n",
    "    # In case of no success, the date closest to the target date is used as the final measurement. \n",
    "    elif not measurements_around_cutoff.empty:\n",
    "        measurements_around_cutoff = measurements_around_cutoff.copy()\n",
    "        measurements_around_cutoff['distance_to_center'] = abs(\n",
    "            (measurements_around_cutoff['measurement_date'] - target_date).dt.days\n",
    "        )\n",
    "        closest_measurement_idx = measurements_around_cutoff['distance_to_center'].idxmin()\n",
    "        final_measurement = measurements_around_cutoff.loc[closest_measurement_idx]\n",
    "    # In case of no success nor completion (delayed dropout), use the last available measurement as the final measurement\n",
    "    elif not measurements_within_window.empty:\n",
    "        final_measurement = measurements_within_window.sort_values('measurement_date').iloc[-1]\n",
    "    # Else: Instant dropout, final_measurement remains None, \n",
    "    # and is set to the baseline measurementin the calculate_outcome_metrics function.\n",
    "    return final_measurement\n",
    "\n",
    "def _calculate_outcome_metrics(baseline_row, final_measurement_row):\n",
    "    \"\"\"\n",
    "    Calculate follow-up lenght and weight loss percentage based on baseline and final measurement.\n",
    "    \"\"\"\n",
    "    # Identify the baseline measurement\n",
    "    baseline_date = baseline_row['measurement_date']\n",
    "    baseline_weight = baseline_row['weight_kg']\n",
    "    # In patients that have at least one followup measurement, identify the end date and final weight, \n",
    "    # to calculate followup length and weight loss in kg and %\n",
    "    if final_measurement_row is not None:\n",
    "        end_date = final_measurement_row['measurement_date']\n",
    "        final_weight = final_measurement_row['weight_kg']\n",
    "        followup_period = (end_date - baseline_date).days\n",
    "        weight_loss_kg = baseline_weight - final_weight\n",
    "        weight_loss_pct = ((baseline_weight - final_weight) / baseline_weight) * 100\n",
    "    # In patients that have no followup measurement (instant dropouts), \n",
    "    # the end date and final weight are set to the baseline values, \n",
    "    # and followup length and weight loss are set to 0. \n",
    "    else: \n",
    "        end_date = baseline_date\n",
    "        final_weight = baseline_weight\n",
    "        followup_period = 0\n",
    "        weight_loss_kg = 0\n",
    "        weight_loss_pct = 0\n",
    "    return {\n",
    "        'end_date': end_date,\n",
    "        'final_weight': final_weight,\n",
    "        'followup_period': followup_period,\n",
    "        'weight_loss_kg': weight_loss_kg,\n",
    "        'weight_loss_pct': round(weight_loss_pct, 2)\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "CORE ANALYSIS FUNCTION\n",
    "\"\"\"\n",
    "\n",
    "def calculate_weight_loss_outcome(patient_data, filtered_measurements, weight_loss_target, window_center, window_span):\n",
    "    \"\"\"\n",
    "    Calculate weight loss outcomes for each patient in a survival analysis-ready format. \n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store results, and group measurements by patient and medical record ID\n",
    "    results = []\n",
    "    grouped_measurements = filtered_measurements.groupby(['patient_id', 'medical_record_id'])\n",
    "    # Iterate through each group within measurements. \n",
    "    for (patient_id, medical_record_id), group in grouped_measurements:\n",
    "        # 1. Identify baseline measurement date and weight\n",
    "        baseline_row = _get_patient_baseline(patient_data, patient_id, medical_record_id)\n",
    "        if baseline_row is None: continue\n",
    "        baseline_date = baseline_row['measurement_date']\n",
    "        baseline_weight = baseline_row['weight_kg']\n",
    "        # 2. Define observation time windows and group measurements within the defined window\n",
    "        # Calculations are done for both the complete observation period, \n",
    "        # as well as the period strictry around the cutoff date, within the defined permissivity window. \n",
    "        min_window_date = baseline_date + timedelta(days=(window_center - window_span))\n",
    "        max_window_date = baseline_date + timedelta(days=(window_center + window_span))\n",
    "        measurements_within_window = group[\n",
    "            (group['measurement_date'] > baseline_date) &\n",
    "            (group['measurement_date'] <= max_window_date)\n",
    "        ].sort_values('measurement_date')\n",
    "        measurements_around_cutoff = group[\n",
    "            (group['measurement_date'] >= min_window_date) &\n",
    "            (group['measurement_date'] <= max_window_date)\n",
    "        ]\n",
    "        # 3. Check whether target weight loss was achieved in the defined time window\n",
    "        target_achieved, first_success_row = _check_target_achievement(\n",
    "            measurements_within_window, baseline_weight, weight_loss_target\n",
    "        )\n",
    "        # 4. Identify the last measurement date within the time window,\n",
    "        # whether based on target achievment or followup completion\n",
    "        final_measurement_row = _determine_final_measurement(\n",
    "            target_achieved, first_success_row, measurements_around_cutoff,\n",
    "            measurements_within_window, baseline_date, window_center\n",
    "        )\n",
    "        # 5. Check for dropout status - instant dropouts are those who have no second measurement, \n",
    "        # while delayed dropouts are those who have not reached target, \n",
    "        # and their final measurement is before the cutoff window. \n",
    "        is_instant_dropout = final_measurement_row is None\n",
    "        is_delayed_dropout = (not target_achieved and\n",
    "                              final_measurement_row is not None and\n",
    "                              final_measurement_row['measurement_date'] < min_window_date)\n",
    "        dropout = is_instant_dropout or is_delayed_dropout\n",
    "        success = target_achieved\n",
    "        # 6. Calculate metrics like final date and weight, followup length and weight lost. \n",
    "        outcome_metrics = _calculate_outcome_metrics(baseline_row, final_measurement_row)\n",
    "\n",
    "        \"\"\"ARE WE GOING TO MODIFY AVG CALCS?\"\"\"\n",
    "\n",
    "        # # 7. \n",
    "        # # --- NEW: Calculate metrics based *always* on the last measurement within the window ---\n",
    "        # actual_last_measurement_row = None\n",
    "        # if not measurements_within_window.empty:\n",
    "        #     actual_last_measurement_row = measurements_within_window.iloc[-1]\n",
    "\n",
    "        # # Use the same helper, but pass the actual last measurement row\n",
    "        # actual_end_metrics = _calculate_outcome_metrics(baseline_row, actual_last_measurement_row)\n",
    "        # actual_wl_pct_at_window_end = actual_end_metrics['weight_loss_pct']\n",
    "        # # --- End NEW ---\n",
    "\n",
    "\n",
    "\n",
    "        # 8. Assemble the result - this is where the output tables' columns are defined. \n",
    "        # If additional variables are inserted at an earlier part of the code, \n",
    "        # they need to be mentioned here as well. \n",
    "        result = {\n",
    "            'patient_id': patient_id,\n",
    "            'medical_record_id': medical_record_id,\n",
    "            'baseline_date': baseline_date,\n",
    "            'end_date': outcome_metrics['end_date'],\n",
    "            'followup_period': outcome_metrics['followup_period'],\n",
    "            'baseline_weight': baseline_weight,\n",
    "            'final_weight': outcome_metrics['final_weight'],\n",
    "            'weight_loss_kg': outcome_metrics['weight_loss_kg'],\n",
    "            'weight_loss_pct': outcome_metrics['weight_loss_pct'],\n",
    "            # \n",
    "            f'{weight_loss_target}pct_achieved': success,\n",
    "            'dropout': dropout,\n",
    "            # Add baseline characteristics safely using .get()\n",
    "            'sex': baseline_row.get('sex'),\n",
    "            'age': baseline_row.get('age'),\n",
    "            'height_m': baseline_row.get('height_m'),\n",
    "            'baseline_bmi': baseline_row.get('bmi'),\n",
    "            'hunger': baseline_row.get('hunger'),\n",
    "            'satiety': baseline_row.get('satiety'),\n",
    "            'emotional_eating': baseline_row.get('emotional_eating'),\n",
    "            'emotional_eating_value': baseline_row.get('emotional_eating_value'),\n",
    "            'quantity_control': baseline_row.get('quantity_control'),\n",
    "            'impulse_control': baseline_row.get('impulse_control')\n",
    "        }\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "MAIN ORCHESTRATION FUNCTION\n",
    "\"\"\"\n",
    "\n",
    "def generate_survival_analysis_datasets(input_connection, output_connection, weight_loss_targets, time_windows, window_span=10):\n",
    "    \"\"\"\n",
    "    The main function to orchestrate the survival analysis process, calling all previously defined functions in an organized manner. \n",
    "    Generate survival analysis datasets for multiple weight loss targets and observation time windows.\n",
    "    Targets and timeframes are defined in the configuration section at the beginning of the code module.\n",
    "    Save data to a separate SQLite database. \n",
    "    \"\"\"\n",
    "    # 1. Load and prepare input data\n",
    "    measurements = load_measurements(input_connection)\n",
    "    medical_records = load_medical_records(input_connection)\n",
    "    patient_data, filtered_measurements = prepare_patient_data(measurements, medical_records)\n",
    "    if patient_data.empty:\n",
    "        print(\"ERROR: Prepared patient data is empty. Cannot proceed.\")\n",
    "        return {}, pd.DataFrame()\n",
    "    # 2. Calculate weight loss outcomes for each target-timeframe combination. \n",
    "    # Targets and timeframes are defined in the config section of the script. \n",
    "    # Initialize a results dictionary and a list for summary statistics. \n",
    "    results = {}\n",
    "    summary_list = []\n",
    "    for window in sorted(time_windows):\n",
    "        for target in sorted(weight_loss_targets):\n",
    "            # Name each instance accordingly, where sa stands for survival analysis, \n",
    "            # and the numbers indicate the time window and target percentage.\n",
    "            name = f\"sa_{window}d_{target}p\"\n",
    "            print(f\"--- Processing: {name} ---\") # Minimal progress indication\n",
    "            result_df = calculate_weight_loss_outcome(\n",
    "                patient_data,\n",
    "                filtered_measurements,\n",
    "                target,\n",
    "                window,\n",
    "                window_span # Defined in config - the permissivity window around the followup cutoff time\n",
    "            )\n",
    "            results[name] = result_df\n",
    "            # Add the calculated instances to the summary statistics list. \n",
    "            if not result_df.empty:\n",
    "                summary_row = {\n",
    "                    'analysis_name': name,\n",
    "                    'weight_loss_target': target,\n",
    "                    'time_window': window,\n",
    "                    'total_patients': len(result_df),\n",
    "                    'achieved_target': int(result_df[f'{target}pct_achieved'].sum()),\n",
    "                    'dropout_count': int(result_df['dropout'].sum()),\n",
    "                    'avg_weight_loss_pct': result_df['weight_loss_pct'].mean() if not result_df['weight_loss_pct'].isnull().all() else 0\n",
    "                }\n",
    "                summary_list.append(summary_row)\n",
    "            else:\n",
    "                 print(f\"WARN: No results generated for {name}. Skipping summary entry.\")\n",
    "    # Turn the summary statistics list into a data frame\n",
    "    summary = pd.DataFrame(summary_list)\n",
    "\n",
    "    # 3. Save the analysis results (9 tables by default) to the SQLite database defined in the config section\n",
    "    print(f\"--- Saving results to output database: {output_db_path} ---\")\n",
    "    # Save individual tables\n",
    "    for name, df in results.items():\n",
    "        print(f\"Saving table: {name} ({len(df)} rows)\")\n",
    "        df.to_sql(name, output_connection, if_exists='replace', index=False)\n",
    "    # Save the summary stats table in the database as well\n",
    "    print(f\"Saving summary table: survival_analysis_summary ({len(summary)} rows)\")\n",
    "    summary.to_sql('survival_analysis_summary', output_connection, if_exists='replace', index=False)\n",
    "    output_connection.commit() # Ensure changes are saved\n",
    "    print(\"--- All results saved successfully ---\")\n",
    "    return results, summary\n",
    "\n",
    "\"\"\"\n",
    "EXECUTION BLOCK\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "This part of the code calls all the functions and executes the code. \n",
    "Currently it has a lot of debug messages and error handling, which might be an overkill, \n",
    "but overall, it should not affect transparency of the code.\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"========== Starting Survival Analysis Script ==========\")\n",
    "    # By default, connections are set to None, and will be established in the try block.\n",
    "    input_conn = None\n",
    "    output_conn = None\n",
    "    try:\n",
    "        # Connect to in-and output databases\n",
    "        print(f\"Connecting to input database: {input_db_path}\")\n",
    "        if not os.path.exists(input_db_path):\n",
    "             raise FileNotFoundError(f\"Input database not found at {input_db_path}\")\n",
    "        input_conn = sqlite3.connect(input_db_path)\n",
    "        print(f\"Connecting to output database: {output_db_path}\")\n",
    "        output_conn = sqlite3.connect(output_db_path)\n",
    "        # Run the main analysis function\n",
    "        results, summary = generate_survival_analysis_datasets(\n",
    "            input_conn,\n",
    "            output_conn,\n",
    "            weight_loss_targets,\n",
    "            time_windows,\n",
    "            window_span\n",
    "        )\n",
    "        # Display summary if successful\n",
    "        if not summary.empty:\n",
    "            print(\"\\n--- Survival Analysis Summary ---\")\n",
    "            print(summary.to_string()) # Use print for console display\n",
    "            print(\"--- End Summary ---\")\n",
    "        else:\n",
    "            print(\"WARN: Analysis completed, but the summary table is empty.\")\n",
    "        print(f\"Analysis data successfully generated and saved to {output_db_path}\")\n",
    "\n",
    "    # Minimal error handling for critical failures\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"ERROR: Database file not found - {e}\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"ERROR: SQLite database error - {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"ERROR: Data processing error - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An unexpected error occurred - {e}\")\n",
    "        # Consider adding traceback for debugging complex errors:\n",
    "        # import traceback\n",
    "        # print(traceback.format_exc())\n",
    "    finally:\n",
    "        # Ensure connections are closed\n",
    "        print(\"Closing database connections...\")\n",
    "        if input_conn:\n",
    "            input_conn.close()\n",
    "        if output_conn:\n",
    "            output_conn.close()\n",
    "        print(\"========== Survival Analysis Script Finished ==========\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
