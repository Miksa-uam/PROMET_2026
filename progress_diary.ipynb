{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APRIL 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- comparing only baseline emotional with baseline weight - bigger sample size than in longitudinal\n",
    "- also, linking baseline emotional with dropping out, and whole program completion (percentage of completers, weight loss at completion)\n",
    "- use frequency of measurements and number of visits as indicators of adherence\n",
    "- 10% WL vs dropout as competing risks (events that prevent the outcome of interest) in a survival model (Fine-Gray model)\n",
    "- making correlation plot between the emotional variables themselves\n",
    "- have a look at physical activity levels, medication, comorbidities and smoking if available, together with weight gain causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### musts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- patients' age: the age variable is missing for some patients. In the SA sql, the age_when_creating_record variable must be used, as that column has no missings in medical records. \n",
    "- correcting for GDPR\n",
    "- when checking if a baseline/final measurement is within the range of a medical record, don't look whether it is within/without the start and end dates. Rather, look if it is within a 10-15-day window of both dates. Sometimes the first measurement is months after the start of a prescription, and that can't be taken as a reliable baseline value. Identifying cases like this can also help spotting loopholes in the analysis pipeline. \n",
    "- when using genetics and considering personalized recommendations, correcting for dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight gain reasons categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chrono - desorden en comidas, desorden horario, jetlag, viajar mucho "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Women's health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUMENTO PREVIO EMBARAZO + POST EMBARAZO\n",
    "2 GRAVIDEZES EM QUE AUMENTOU DE PESO ATÉ AOS 90KG E DEIXOU DE FUMAR. NA 1º GRAVIDEZ ATÉ CONSEGUIU VOLTAR QUASE AO SEU PESO MAS NA SEGUNDA GRAVIDEZ JUNTAMENTE COM O TER DEIXADO DE FUMAR NÃO CONSEGUIU \n",
    "MÃE DE 2 FILHOS (3 E 5 ANOS DE IDADE), POUCO DESCANSO (PRIVAÇÃO DE SONO). TAMBÉM ME DIZ QUE SOFREU ABORTO EM AGOSTO/2021 E EMOCIONALMENTE TAMBÉM DESCOMPENSOU NA ALIMENTAÇÃO. DIZ QUE NÃO COME \"MAL\", MAS PECA NAS QUANTIDADES.\n",
    "EMBARAZO \n",
    "3 EMBARAZOS \n",
    "UMA CIRURGIA DE REMOÇÃO DO UTERO EM 2021 E FOI A PARTIR DAÍ QUE O PESO FICOU DESCONTROLADO\n",
    "PREMENOPAUSIA, DEJAR DE FUMAR , CAMBIO DE TURNO\n",
    "Embarazo, falta motivación...\n",
    "menopausia \n",
    "MENOPAUSA + IDADE\n",
    "Embarazo\n",
    "Dos embarazos\n",
    "Después del embarazo subió mucho de peso, quiere perder hasta llegar a los 80\n",
    "Abortos y embarazos \n",
    "Hipotiroidismo y premenopausia falta de ejercicio. Tiene alimentación saludable. \n",
    "Menopausia y desestabilización de la tiroides.\n",
    "AUMENTO PROGRESIVO - TERCER EMBARAZO SUBIO MUCHO DE PESO - NO SE HA CUIDADO NUNCA Y COME CANTIDADES\n",
    "Perimenopausia\n",
    "2 EMBARAZOS \n",
    "menopausia, mucho stress\n",
    "PROGRESIVO: 2 EMBARAZOS DESCONTRALADOS\n",
    "REGLA IRREGULARES\n",
    "SEDENTARISMO - DEIXOU DE FAZER DESPORTO (HÁ 10 ANOS) + 2 GRAVIDEZES (1 5 ANOS E OUTRA DE 8 ANOS)\n",
    "GRAVIDEZ  (MENINO - 17 MESES) E REGRESSO AO TRABALHO\n",
    "PREMENOPAUSIA\n",
    "MORAVA FORA E NAS MUDANÇAS PARA PORTUGAL E MUDANÇA DE ROTINAS E SÓ AÍ GANHOU 10 KG E DEPOIS ENGRAVIDOU E CHEGOU AOS 95KG\n",
    "O SISTEMA NERVOSO SÓ LHE DÁ PARA COMER PORCARIAS\n",
    "FOI MÃE HÁ 4 ANOS MAS O PESO DESCAMBOU E TEM SIDO MUITO DIFICIL BAIXAR O PESO. ACHA QUE TAMBÉM ESTÁ NUMA FASE DE PRÉ-MENOPAUSA E DEPOIS PARECE QUE NÃO AJUDA\n",
    "Embarazo hace 5 años + pandemia\n",
    "MENOPAUSA (ACHA QUE CONTRIBUIU UM BOCADINHO) E NÃO SABE BEM O PORQUÊ\n",
    "GRAVIDEZ\n",
    "3 invitro + embarazo \n",
    "Endometriosis + histerectonia.\n",
    "Premenopausia\n",
    "EMBARAZO, VIDA SEDENTARIA, ANSIEDAD \n",
    "MENOPAUSIA, STRESS, COME DESORGANIZADO\n",
    "DEPOIS DO NASCIMENTO DO ULTIMO FILHO (HÁ 11 ANOS) COMEÇOU A DESCAMBAR E COM A MENOPAUSA NÃO AJUDOU\n",
    "Sedentarismo, menopausia, tiene picos de ansiedad, desorden en las comidas por el trabajo. \n",
    "2 EMBARAZOS Y ANSIEDAD CON LA COMIDA 7 MESES DE LA ULTIMA \n",
    "OVARIOS POLIQUISTICOS, RESISTENCIA A LA INSULINA. \n",
    "QUANDO ENGRAVIDOU AUMENTOU 25KGS E NUNCA MAIS RECUPEROU. 2 GRAVIDEZES.\n",
    "ANSIEDAD POR MENOPAUSIA\n",
    "IDADE + MENOPAUSA\n",
    "Menopausia\n",
    "EMBARAZOS\n",
    "desajustes hormonales\n",
    "MENOPAUSIA\n",
    "OPERACION UTERO DE URGENCIA MÁS TTO HORMONAL - EMBARAZO\n",
    "le quitaron el útero\n",
    "menopausia + toma vino habitualmente\n",
    "EMBARAZO\n",
    "MENOPAUSIA\n",
    "Menopausia\n",
    "Dejadez y tendencia a engordar + menopausia\n",
    "EMBARAZO, ESTRES \n",
    "MENOPAUSIA\n",
    "embarazos pandemia\n",
    "MENOPAUSIA\n",
    "Ansiedad, ovarios poliquísticos\n",
    "post embarazo después de 2 niños, diabetes gestacional \n",
    "menopausia\n",
    "MENOPAUSIA\n",
    "embarazos, menopausia\n",
    "Menopausia\n",
    "Menopausia, sedentaria\n",
    "MENOPAUSIA\n",
    "MENOPAUSIA, ESTRES EN CASA \n",
    "menopausia, malos habitos\n",
    "MENOPAUSIA PRECOZ, TRATAMIENTO DE FERTILIDAD\n",
    "embarazo y malos  hábitos\n",
    "embarazo,come mucho  productos con azúcar\n",
    "Pastillas para quedar embarazada\n",
    "EMBARAZOS,COME MUCHO EN RESTAURANTES POR TRABAJO\n",
    "EMBARAZO, REDUCE ACTIVIDAD\n",
    "2 perdidas de embarazo y le cuesta perder peso\n",
    "EMBARAZOS, CONFINAMIENTO\n",
    "Menopausia y exceso de pan. Sedentarismo.\n",
    "endometriosis - tratamiento hormonalque le ha dado mucha ansiedad\n",
    "A SEGUIR TER FICADO GRÁVIDA. GANHOU ESTE PESO PÓS GRAVIDEZ. DEIXA DE COMER QUANDO ESTÁ MAIS STRESSADA E ASSIM. \n",
    "EMBARAZO, ABORTO Y OTRAS COSAS QUE LE INFLUYEN EN EL PESO. NO TIENE HAMBRE PERO COME MAL. \n",
    "Ser madre\n",
    "FEZ TTO DE FERTILIZAÇÃO IN VITRO - DESCONTAVA AQUI NA COMIDA E A NIVEL EMOCIONAL FOI COMPLICADO\n",
    "EMBARAZO Y PANDEMIA (ESTRES)\n",
    "SE SALTA COMIDAS. TUBO UN ABORTO MOTIVO PRINCIPAL POR EL  QUE EMPEZÓ A GANAR PESO. \n",
    "MENOPAUSA\n",
    "PREMENOPAUSIA - DESAJUSTE HORMONAL CON SOFOCOS\n",
    "AUMENTO DE PESO A RAIZ DEL EMBARAZO\n",
    "MATERNIDAD FALTA DE CUIDADOS DESPUES. \n",
    "HA AUMENTADO DE PESO POR SEDENTARISMO, MENOPAUSIA...\n",
    "MENOPAUSIA \n",
    "PREMENOPAUSIA\n",
    "Embarazo hace 10 años + Sedentarismo por problemas fisicos + Se ha puesto el DIU\n",
    "menopausia, dejar de fumar...\n",
    "MATERNIDAD \n",
    "Dos embarazos\n",
    "Embarazos ha notado cambios y le cuesta perder ese peso. Le gusta dulce \n",
    "2 GRAVIDEZ + DESCONTROLO EMOCIONAL QUE A LEVOU A COMPENSAR COM A COMIDA\n",
    "NO FINAL DA 1ª GRAVIDEZ FEZ DIETA 3 PASSOS E RECUPEROU O PESO. APÓS A 2ª GRAVIDEZ NUNCA CONSEGUIU BAIXAR DOS 60KG FICANDO DEPOIS COM OS 64KG E DEPOIS COM OS PROBLEMAS NO TRABALHO GANHOU MAIS 4 KG. TEVE TAMBÉM O FALECIMENTO DOS PAIS QUE TAMBÉM NÃO AJUDOU. \n",
    "Dos embarazos\n",
    "EMBARAZO, BUENO HABITOS Y COME SANO\n",
    "MENOPAUSIA\n",
    "EMBARAZO SEGUIDOS \n",
    "MENOPAUSIAEMBARAZOS\n",
    "MENOPAUSIA, CAMBIO HORMONAL\n",
    "GRAVIDEZ - AUMENTOU DE PESO E NÃO CONSEGUIU PERDER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mental health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MALA ALIMENTACION, MUERTE DE FAMILIARES \n",
    "MUDANÇA DE CIDADE RECENTE - CASTELO BRANCO. TEM AO SEU CUIDADO OS 2 FILHOS DE 4 E 6 ANOS, O SEU MARIDO AINDA NÃO CONSEGUIU TRANSFERENCIA DE TRABALHO E POR ISSO ESTÁ MAIS SOBRECARREGADA EM CASA. DESIQUILIBRIO ALIMENTAR. COMPENSAÇÃO EMOCIONAL NA COMIDA.\n",
    "ANSIEDAD, DESORGANIZADA EN SUS COMIDAS\n",
    "Confinamiento, mucho estrés\n",
    "ENFERMEDAD DE SU MADRE, PANDEMIA\n",
    "Ansiedad\n",
    "SEDENTARIO Y ANSIEDAD\n",
    "Ansiedad\n",
    "Depresión\n",
    "CORTISOL ALTO DESDE HACE 6 AÑOS, MUCHO ESTRES PERO NO LE AFECTA A LA MANERA DE COMER\n",
    "MUITO STRESS + IDADE \n",
    "ansiedad momento\n",
    "Estrés laboral\n",
    "Ansiedad noches / No desayuna\n",
    "VIDA MUITO STRESS E COMPENSA AS EMOÇÕES COM A ALIMENTAÇÃO\n",
    "DURANTE ALGUM TEMPO CONSEGUIU MANTER A ALIMENTAÇÃO MAS DEPOIS TEVE MUITAS SITUAÇÕES DE STRESS QUE LHE DEU PARA COMER\n",
    "TIENE ATRACONES CUANDO ESTA ESTRESADA, ES POR TEMPORADAS\n",
    "ESTRÉS, ANSIEDAD POR EL TRABAJO. HA PASADO A SER PROFE DE GUARDERIA A PROFE DE UNI\n",
    "PROBLEMAS FAMILIARES: DETECTARON UN CÁNCER A SU HIJO Y YA TODO SE FUE AL TRASTE COMENTA\n",
    "ESTRÉS, PANDEMIA, MUERTE PADRE\n",
    "Difícil de controlar algunas noches a nivel emocional. \n",
    "Ansiedad + Dejar de fumar\n",
    "FOME EMOCIONAL\n",
    "la vez anterior llego a 91 kg, pero por estres, come por ansiedad y por eso subio peso\n",
    "STRESS, ANSIEDAD, TRABAJAR FUERA DE CASA\n",
    "A raiz de la pandemia + ansiedad\n",
    "LOS ULTIMOS 2 AÑOS, SU PADRE FALLECIÓ Y MUCHA ANSIEDAD\n",
    "STRESS, VIAJA MUCHO, COMER MUY DESORDENADO\n",
    "Ansiedad\n",
    "comer mucho desorden, estrés\n",
    "ESTÁ A TOMAR ANTIDEPRESSIVOS + VITAMINAS. DIZ QUE ANSIEDADE E NERVOSISMO DÁ-LHE PARA COMER SÓ PORCARIAS. \n",
    "ABORTO Y A RAÍZ DE AHÍ MALOS HABITOS ALIMENTARIOS\n",
    "ANSIEDAD - COMER DULCE\n",
    "PROBLEMA FAMILIAR, COMIDAS DESORGANIZADAS\n",
    "DEPRESION \n",
    "FOME EMOCIONAL, GULA\n",
    "Situación familiar complicada a nivel anímico\n",
    "MUCHO STRESS\n",
    "Febrero ha tenido un pico de estres laboral\n",
    "NÃO SABE. ACHA QUE SÃO VÁRIOS FATORES. MUITO STRESS E COM MUITOS PRAZOS NO TRABALHO E NOTA QUE A COMIDA É UM POUCO O SEU REFUGIO\n",
    "STRESS + COMIDA + COMPENSAÇÕES COM A COMIDA\n",
    "TIENE UNA VIDA MUY ESTRESANTE, Y CUANDO LLEGA LA NOCHE COME MUCHISIMO\n",
    "NÃO SABE BEM. DIZ QUE É MUITO STRESSADA E ANSIOSA E NÃO TEM FOME MAS SIM VONTADE DE COMER\n",
    "MUCHA ANSIEDAD POR LA NOCHE\n",
    "ESTRES COME LO QUE LE APETECE FUERA DE TIEMPO. \n",
    "Muere un familiar y esta cuidado a otro\n",
    "Estres\n",
    "Estrés, trabaja sedentario. \n",
    "DIZ SER MUITO ANSIOSA E POR ISSO TEM EPISÓDIOS DE COMPULSÃO ALIMENTAR FREQUENTES (GERALMENTE AO FINAL DO DIA - ENTRE AS 17H-20H00).\n",
    "LE CUESTA MANTENER UN PESO ESTABLE. TIENE MUCHOS ANSIEDAD \n",
    "Estrés\n",
    "Estrés en el trabajo\n",
    "DEPRESIÓN Y ANSIEDAD \n",
    "ANSIEDADE - MEDICADA\n",
    "ESTRES Y ANSIEDAD\n",
    "ANSIEDAD, ESTRES , FALTA DE MOVILIDAD \n",
    "PROBLEMAS PERSONALES MUERTE DE UN FAMILIAR \n",
    "ANSIEDAD \n",
    "Malos hábitos. Dos años sin trabajar por la pandemia, ansiedad y depresión.\n",
    "ANSIEDAD Y EMBARAZOS \n",
    "A RAÍZ DE PANDEMIA + VERANO PORQUE TENIA ANSIEDAD (esta en paro) Y SE ABURRÍA\n",
    "ANSIEDAD\n",
    "CONFINAMENTO + DIVÓRCIO\n",
    "subida de peso por problemas familiares.\n",
    "ALIMENTAÇÃO + SEDENTARISMO + EMOCIONAL\n",
    "ESTRES EN EL TRABAJO, CAMBIOS HORMONALES\n",
    "Ansiedad y estrés \n",
    "comer mal, estress\n",
    "ANSIEDAD POR PROBLEMAS LABORALES\n",
    "DEPRESION\n",
    "Estrés en el trabajo y horarios cambiantes \n",
    "Estrés y poco ejercicio\n",
    "PROBLEMAS PERSONALES, DESORDEN\n",
    "ANSIEDAD, MURIO SU MADRE HACE UN AÑO\n",
    "MUCHAS ANSIEDAD POR TEMAS PERSONALES\n",
    "Tubo problemas de depresión en el pasado, ahora esta más estable y animada.\n",
    "Problemas familiares y mucha ansiedad\n",
    "Ansiedad\n",
    "Influyen emociones y dificultad física. \n",
    "MUCHA ANSIEDAD POR CORTICOIDES\n",
    "Ansiedad sobre todo por las tardes.\n",
    "Antidepresivos \n",
    "come por ansiedad, come muy rápido\n",
    "ANSIEDAD\n",
    "CAUSAS PERSONALES Y DE TRABAJO \n",
    "22kg, pandemia,  ha tenido mucha ansiedad. \n",
    "HACE 2 AÑOS SE DESMADRÓ - MUCHO STRESS \n",
    "ANSIEDAD, PANDEMIA, MUERTE DE SU PADRE\n",
    "DESCONTROL, ANSIEDAD CON LA COMIDA \n",
    "Depresión\n",
    "MUCHA ANSIEDAD\n",
    "MUCHO ESTRES EN EL TRABAJO\n",
    "ansiedad por picoteo por todo - toma ansiolíticos\n",
    "INSOMNIO - LE PROVOCA ATRACONES NOCTURNOS\n",
    "ESTRES POR TRABAJO, ANSIEDAD POR COMER DULCE O MALCOMER\n",
    "ANSIEDAD, NO EJERCICIO\n",
    "CONFINAMIENTO Y TRABAJA EN LA SANIDAD PROBLEMAS DE ANSIEDAD. \n",
    "Estrés en el trabajo...\n",
    "hija con alteraciones cromosómicas y le genera mucha ansiedad\n",
    "ACHA QUE É EMOCIONAL. TEM TIDO UNS PROBLEMAS PRIVADOS (PAI FALECEU E SEPAROU-SE) E EMPRESARIAL (EMPRESA NÃO VAI BEM) E DEPOIS DA GRAVIDEZ NOTA QUE MUDOU MUITO\n",
    "HACE 5 AÑOS MURIÓ SU MARIDO Y COGIÓ PESO\n",
    "por la noche tiene mas ansiedad\n",
    "ENTROU EM DEPRESSÃO EM 2021 E COMEÇOU A AUMENTAR PESO GRADUALMENTE DEVIDO A COMPULSÃO ALIMENTAR. ATUALMENTE JÁ NÃO TRABALHA POR TURNOS (HORÁRIO 10-19H00).\n",
    "Estres en el trabajo\n",
    "SIEMPRE ANSIEDAD,LE DA POR COMER, SE DESPIERTA POR LA NOCHE PARA PICAR\n",
    "ANSIEDAD, DESCONTROL COMIDAS, DORMIR POCO\n",
    "ansiedad por muerte de familiar\n",
    "DIVORCIO\n",
    "DEJADEZ, SEDENTARISMO, CAMBIOS HORMONALES, ANSIEDAD, DEPRESION\n",
    "Menopausia y ansiedad\n",
    "STRESS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medical condition/injury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO PODER MOVERSE POR DOLOR LUMBARES\n",
    "ROTURA DE MENISCO, DETUBO EJERCICIO Y NO SE HA SABIDO CONTROLAR + MUERTE DE SU PADRE\n",
    "MUCHO REPOSO POR PROBLEMA CON OPERACION DE CATARATAS, LESION EN LA ESPALDA\n",
    "REDUCE EJERCICIO POR OPERACIONES DE RODILLA Y CAIDAS \n",
    "ACCIDENTE EN OCTUBRE Y HA ESTADO DE REPOSO\n",
    "FIBROMIALGIA\n",
    "HIPOTIROIDISMO\n",
    "TIROIDITE DE HASHIMOTO E DEPOIS COM ESTA ATRITE REUMATOIDE NÃO AJUDOU E NÃO CONSEGUIU SAIR DESTE PESO\n",
    "NOTA QUE ESTÁ MUITO INFLAMADA E MUITO INCHADA\n",
    "HIPOTIROIDISMO\n",
    "Cx espalda - mucho reposo y medicación y corticoides, muchas migrañas - 1 año sin regla (menopausia)\n",
    "FEZ UMA ROTURA DE LIGAMENTOS GRAVE E FOI OPERADA E FICOU ENTÃO 1 ANO PARADA SEM QUALQUER ATIVIDADE FISICA\n",
    "NO HA HECHO MANTENIMIENTO, POR OPERACION MUCHO REPOSO\n",
    "TIROIDES\n",
    "HIPOTIROIDES ANTES EL EMBARAZO PERO AHORA BIEN\n",
    "HIPOTIROIDISMO HACE 3 AÑOS\n",
    "CANCER DE MAMA HACE 6 AÑOS, MEDICACION, DEPRESION, AUN NO TIENE ALTA ONCOLOGICA\n",
    "DIAGNOSTICADA COM LIPEDEMA - NOTA QUE QUANDO AS PERNAS FICARAM MAIS INFLAMADAS O PESO SUBIU\n",
    "HA DEJADO DE HACER DEPORTE POR LO QUE HA SUBIDO DE PESO\n",
    "LUXACION HOMBRO\n",
    "LESION\n",
    "FRACTURA DE L1.\n",
    "Sedentarismo\n",
    "Sendentarismo a raiz de la pandemia + lesión\n",
    "TROCANTERITIS - REPOSO, MENOPAUSIA\n",
    "LESIÓN \n",
    "BALON GASTRICO\n",
    "SE ROMPIO EL PERONE Y REPOSO UNOS MESES\n",
    "SEMPRE TEVE EXCESSO DE PESO. NÃO TEM PESO HABITUAL. PESO MUITO IO-IO, EM PROCESSOS DE EMAGRECIMENTO CONTÍNUOS. BANDA GÁSTRICA EM 2009 (CHEGOU AOS 73KG), REMOVEU EM FEVEREIRO DE 2022 DEVIDO A ESOFAGITE DE REFLUXO.\n",
    "Sedentarismo\n",
    "DEIXOU DE FAZER DESPORTO\n",
    "PAROU DE FUMAR HA 2 ANIOS E TEVE DE PARAR AF HA 6 MESES PORQUE TORCEU OS 2 PÉS (INFLITRAÇOES COM CORTISONA E GEL HIALURONICO). DIFICL DE PARAR DE COMER MESMO SABENDO QUE TA CHEIA E PODE FICAR MAL. APTENCIA PARA DOCES. FAZ PA, ALM E JANTAR. COME MT AO JANTAR PORQUE PASSA H SEM COMER A TARDE. AS VEZES N ALMOÇA TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Physical activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDAD, MENOS ACTIVIDAD FISICA\n",
    "DEIXOU DE TREINAR\n",
    "SEDENTARISMO, DEJA DEPORTE Y MALOS HABITOS \n",
    "NO PUEDE HACER AF, AHORA HA RETOMADO (HACE 2 MESES)\n",
    "SEDENTARISMO\n",
    "IDADE + TIROIDE + FALTA DE AF\n",
    "Cambio de hábitos en salud y ejercicio. \n",
    "VIDA SEDENTÁRIA + NÃO TER HORAS REGULARES PARA AS REFEIÇÕES. FOI MÃE HÁ 4 ANOS E NÃO CONSEGUIU BAIXAR MAIS\n",
    "FAZIA CAMINHADAS 8KM A 12KM TODOS OS DIAS ANTES DA PANDEMIA E DEPOIS DA PANDEMIA FICOU MAIS SEDENTÁRIO\n",
    "Sedentarismo 9h sentada\n",
    "DEIXOU DE JOGAR FUTEBOL E TORNOU-SE MUITO SEDENTÁRIO. PARA ALÉM DISTO DEPOIS DE JOGAR FUTEBOL FICOU COM UMA DEPRESSÃO NERVOSA E TOMOU \n",
    "Protesis de cadera, ya que antes hacía mucho deporte\n",
    "FILHOS + ESTILO DE VIDA + DEIXOU DE PRATICAR DESPORTO\n",
    "FOI JOGADOR DE FUTEBOL MAS COM 14 ANOS SOUBE QUE TINHA UM PROBLEMA NO CORAÇÃO E TEVE DE PARAR COM O EXERCICIO FISICO E DEPOIS COMO NÃO TINHA GRANDE CUIDADO NA ALIMENTAÇÃO FOI AUMENTANDO O PESO. \n",
    "INICIO DE VIDA PROFISSIONAL. FALTA DE TEMPO PARA FAZER AF + STRESS NO TRABALHO COM UMA ALIMENTAÇÃO POUCA CUIDADA\n",
    "PANDEMIA + DESLEIXO + SEDENTARISMO (TRABALHO)\n",
    "SEDENTARISMO (TELE TRABALHO) + ALIMENTAÇÃO\n",
    "COM A PANDEMIA HABITUOU-SE A ESTAR MUITO TEMPO SENTADA + IDADE\n",
    "IDADE + POUCA AF (PROBLEMA DE JOELHOS EM QUE TEVE DE PARAR COM A AF - TINHA MENOS 10KG/12KG) \n",
    "FOI ATLETA DE ALTA COMPETIÇÃO E QUANDO DEIXOU O DESPORTO NOTOU MUITAS MUDANÇAS. GOSTA MUITO DE COMER E DE IR COMER FORA. GRAVIDEZ - PERDEU LOGO 10KG NA SEMANA A SEGUIR AO PARTO E ATÉ CHEGOU AOS 68KG MAS DEPOIS COM A PANDEMIA O PESO DESCONTROLOU\n",
    "Deja de hacer ejercicio y comer desordenado. No influyen las emociones a la hora de comer \n",
    "Trabajo sedentario \n",
    "Cambio de vida a vida sedentaria\n",
    "TELETRABAJO- SEDENTARISMO- COME MAS-PICOTEO- NO DEPORTE\n",
    "SEDENTARISMO\n",
    "INACTIVIDAD\n",
    "Zaro actividad fisica\n",
    "SEDENTARIA DESDE HACE 4 AÑOS\n",
    "SEDENTARISMO\n",
    "Pandemia, dejo de hacer ejercicio. \n",
    "ANTES HACIA MUCHO DEPORTE, COME MUCHO Y LO QUE LE GUSTA \n",
    "Vida sedentaria \n",
    "SEDENTARISMO + MALOS HORARIOS\n",
    "Sedentarismo, inicio de relación \n",
    "Poco tiempo deporte\n",
    "Come y no hace ejercicio \n",
    "MUITO TEMPO SENTADO EM CASA. ALGUMAS LIMITAÇÕES TAMBÉM A FAZER AF POR PROBLEMAS NA ANCA QUE IMPOSSIBILITA MUITAS AF.\n",
    "trabajo sedentario, comer fuera\n",
    "UMA ALTURA EM QUE ESTEVE MUITO SEDENTÁRIA - ESTAVA A FAZER TESE DE MESTRADO - 2 ANOS\n",
    "SEMPRE FOI MAGRINHA (PESO HABITUAL 58-60KG) PESO MAX = PESO ATUAL =90KG COMEÇOU A AUMENTAR PESO QUANDO ENTROU NA FACULDADE E QUANDO DEIXOU DE FAZER DESPORTO (GINÁSTICA DE COMPETIÇÃO - TREINOS 3H/DIA). \n",
    "PROGRESIVO DESDE HACE 3 AÑOS, DEJÓ LA AF. TRABAJA CON MÁS GUARDIAS Y COME DE GLOVO\n",
    "sedentarismo, no cuidar la alimentacion\n",
    "MEDICAÇÃO\n",
    "CONFINAMENTO - MUITO TEMPO EM CASA E TER PARADO A AF. ACHA QUE NÃO COME MAL MAS GOSTA DE DOCES E NÃO TEM TIDO O CUIDADO DE EVITAR OS DOCES.\n",
    "FAZIA MUITO DESPORTO E QUANDO FOI PARA A FACULDADE DEIXOU DE FAZER DESPORTO\n",
    "PROBLEMAS FISICOS. FOI OPERADA A UM PE E COMEÇOU A GANHAR PESO. JÁ FOI OPERADA 4 OU 5 X. FOI TAMBÉM OPERADA A UMA HERNIA ABDOMINAL.\n",
    "TRABAJO NUEVO MUY ESTRESANTE, DE MUCHO DEPORTE A SEDENTARISMO\n",
    "Hacia mucho deporte y por lesión\n",
    "DESARREGLOS EN LA ALIMENTACION, SEDENTARISMO, PROBLEMA DE ESPALDA\n",
    "sedentarismo\n",
    "SEDENTARISMO + NOTA QUE TEM MAIS DIFICULDADE EM PERDER PESO\n",
    "VIDA MAIS SEDENTÁRIA\n",
    "TRABAJO SEDENTARIO\n",
    "sedentaria, se salta comidas\n",
    "TRABALHO MUITO SEDENTÁRIO. DEIXOU DE PRATICAR DESPORTO COM OS AMIGOS (JOGAVA FUTEBOL 2X/SEMANA). ESTÁ A CONSTRUIR A SUA CASA E DIZ QUE DESDE QUE INICIOU COME MAIS. \n",
    "VIDA MAIS SEDENTÁRIA\n",
    "Rotura de meniscos y tendones por accedente de tráfico. \n",
    "NO MANTENIMIENTO, DESORDEN ABSOLUTO, MALOS HABITOS\n",
    "COMER MUCHO Y NO MOVERSE NADA\n",
    "En la familia todo gira en torno a la comida\n",
    "Al venir a vivir a España, menos acceso a fruta y verdura pq están mas malas.\n",
    "Otras dietas sin mantenimiento.\n",
    "Ha hecho mil dietas\n",
    "ALIMENTAÇÃO DESIQUILIBRADA. SEDENTARISMO. STRESS LABORAL.\n",
    "tiene un restaurante suyo - suele comer en el restaurante\n",
    "En general un poco de todo, mal comer picotea entre horas \n",
    "Le gusta mucho la lecha 1 lt  de leche al día semi \n",
    "COMER DESORDENADAMENTE\n",
    "GOSTA DE COMER E AO FIM DE SEMANA BEBE UM VINHO E/OU CERVEJA\n",
    "mucho picoteo por las noches (vino, jamón, queso, patatas)\n",
    "VÁRIAS TENTATIVAS DE DIETA SEM SUCESSO. FAZ PSICOTERAPIA PARA TRATAR COMPULSÃO ALIMENTAR.\n",
    "comer capricho en las meriendas, comer fuera de casa a diario y elegir por placer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eating habits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le gusta comer mucho dulce, galletas, bizcocho, \n",
    "COMIAN MAL CON EVENTOS \n",
    "COMER A MAIS\n",
    "SE DESRAGULA CON LA ALIMENTACION. NO HA COMIDO BIEN NI HA HECHO EJERCICIO. \n",
    "MALOS HÁBITOS ALIMENTICIOS (dulce) Y COME MUY RAPIDO\n",
    "DESIQUILIBRO ALIMENTAR \n",
    "PICOTEA MUCHO. EL FIN DE SEMANA ES CUANDO MEJOR LO HACES (3 COMIDAS/DÍA)\n",
    "Mala alimentación\n",
    "la comida más grande es la cena\n",
    "TIENE ANTOJOS \n",
    "PICOTEA ENTRE HORAS, MUCHO DESORDEN HORARIO\n",
    "Come con estrés y fuera de casa por trabajo \n",
    "Influyen las emociones a la hora de comer\n",
    "COMER DE MAS, SEDENTARISMO\n",
    "EDAD, MALA ALIMENTACION\n",
    "malos hábitos, picotea últimamente\n",
    "DESORDEN PICOTEO\n",
    "PICOTEA ENTTRE HORAS: GALLETAS, CHOCOLATE\n",
    "FALTA DE CUIDADO ALIMENTAR\n",
    "HA HECHO VARIOS TIPOS DE DIETA (KETO, HERBALIFE,...), ATRACONES....\n",
    "ha comido mal durante muchos años. Ha hecho otras dietas. \n",
    "COME MAS LOS ULTIMOS AÑOS\n",
    "Mala alimentación, familia con sobrepeso. Desordenada no come en toda la mañana y come una vez o 2 a día. Cocina para la familia \n",
    "Comida rápida por falta de tiempo\n",
    "Mucho hidrato \n",
    "IDADE + COMER MUITO TARDE + SEDENTARISMO + GOSTA DE COMER\n",
    "Trabajo (Come en restaurantes)\n",
    "DEIXOU DE FUMAR HÁ 8 ANOS + MENOPAUSA + COME MUITA COISA QUE FAZ MAL. GOSTA MUITO DO PETISCO\n",
    "DESCONTROLO COMPLETO NA ALIMENTAÇÃO\n",
    "HA IDO COGIENDO POCO A POCO DESDE OCTUBRE, PORQUE SE FUE OLVIDANDO DE LAS PAUTAS. CENAS FUERA DE CASA, CELEBRACIONES.\n",
    "NO HACER MANTENIMIENTO, FALTA DE TIEMPO\n",
    "NO MANTENIMIENTO, CAMBIOS EN LA VIDA, DESORDEN\n",
    "NO MANTENIMIENTO, COMIDA RAPIDA, STRESS LE PROVOCA PICAR DULCE\n",
    "NO HIZO MANTENIMIENTO\n",
    "NO MANTENIMIENTO\n",
    "REFERE QUE O NATAL E A CABEÇA NÃO FORAM SEUS AMIGOS\n",
    "SIEMPRE DIETA RESTRICTIVA PERO DESDE EL VERANO HASTA AHORA HA COMIDO SIN TANTO CONTROL\n",
    "HACE TIEMPO HACIENDO DIETA Y NO CONSIGUE BAJAR DE PESO\n",
    "DESORDEN Y MAL COMEDORA, NO LE GUSTAN LAS VERDURAS, NO TOMA LEGUMBRES\n",
    "Otras dietas\n",
    "mucho picoteo por aburrimiento\n",
    "Descontrol horario + gran comedor\n",
    "COME DE FORMA DESEQUILIBRADA\n",
    "MALA RELACIÓN CON LA COMIDA\n",
    "MUCHO CAFES DESCAFEINADOS, MUCHO DESPORDEN HORARIOS - CENA MUCHA ANSIEDAD Y SE DA EL ATRACON - POR EL DULCE\n",
    "trastornos por atracon - ingiere cantidades muy grandes a diario\n",
    "COMER NÃO EM QUANTIDADE MAS EM QUALIDADE. COMER MUITO PÃO E DOCES . MUITO GULOSA\n",
    "PANDEMIA MAS DIZ QUE TEM ABUSADO NA ALIMENTAÇÃO E NÃO TEM FEITO AF\n",
    "PICOTEO POR LAS TARDES, ESPEOR MOMENTO\n",
    "COMER MAL, SIN HORARIOS, \n",
    "Perdió mucho con Naturhouse\n",
    "PICOTEO FRUTOS SECOS, YOGURES, DESPUES DE CENAR LECHE CON CACAO\n",
    "PICOTEO POR LAS TARDES - FRUTOS SECOS, PATATAS - ANSIEDAD POR COMER DE CARA A LA MAÑANA\n",
    "COME MUITO E TEM MUITA FOME. ADORA DOCES E É MUITO SEDENTÁRIA\n",
    "Fanta o coca cola el fin de semana \n",
    "Le gusta comer y beber vino \n",
    "Malos hábitos - hambre emociona- picoteo\n",
    "Desorden de comidas\n",
    "MALCOMER\n",
    "HA PROBADO MUCHAS DIETAS, PERO LE CUESTA DESPUES HACE EL MANTENIMIENTO\n",
    "Comidas fuera de casa\n",
    "malos habitos, desorden alimentario. Descontrol\n",
    "Le cuesta desayunar y hace ayuno intermitente \n",
    "PICOTEA MUCHO, MALA ALIMENTACION\n",
    "POR CANSANCIO NO COME\n",
    "COME FUERA Y VIAJA MUCHO POR TRABAJO\n",
    "picar entre horas, vida social, poca AF\n",
    "Con el tiempo ha ido cogiendo peso por sedentarismo + malos hábitos alimentarios\n",
    "Le gusta mucho el dulce y comer\n",
    "Malos hábitos\n",
    "PESO MINIMO EM IDADE ADULTA 58KG (HÁ CERCA DE 26 ANOS) PESO MAX EM IDADE ADULTA = 86KG (HÁ CERCA DE 5 ANOS QUANDO DEIXOU DE FUMAR) PESO HABITUAL RONDA OS 70KG NO ÚLTIMO ANO. DIZ-ME QUE TODA A VIDA VIVEU EM DIETA, MAS POR VEZES ENTRA EM DESIQUILIBRIO ALIMENTAR E É QUANDO AUMENTA DE PESO.\n",
    "NOTA QUE FICA COM ANSIAS DE COMER DOCES\n",
    "LE GUSTA COMER BIEN, DURANTE UN TIEMPO SEDENTARISMO\n",
    "HABITOS ALIMENTARES\n",
    "PICOTEA EN EL RESTAURANTE SOLO HACE 1 COMIDA AL DIA. \n",
    "No se cuida con cantidades. \n",
    "malos hábitos alimentarios\n",
    "COMER MAL\n",
    "PICOTEO\n",
    "CON LOS PROBLEMAS, ES INCAPAZ DE SEGUIR LA DIETA Y ACABA DESCONTROLANDO\n",
    "NO HACE MANTENIMIENTO\n",
    "picotea\n",
    "volver a los hábitos anteriores, picoteo y festividades\n",
    "COMER MUCHO, MUCHOS ACTOS SOCIALES\n",
    "ABRIU UM CAFÉ BIOLOGICO COM BOLOS E ASSIM E METEU-SE A COMER AQUELAS GOSTOSURAS\n",
    "DICE QUE LLEVA TODO LA VIDA A DIETA\n",
    "Cantidades\n",
    "No desayuno ni media mañana. \n",
    "picoteo por las tardes frutos secos, queso, patatas fritas - desorden de comidas por picoteo\n",
    "PICOTEA\n",
    "MALOS HABITOS ALIMENTARIOS. MUCHO CAFE, POCAS COMIDAS, EN LA HORA DE LA MERIENDA HACE ATRACONES (ANSIEDAD)\n",
    "COMER MAL\n",
    "ADICTA A LA COCA ZERO\n",
    "MUCHO DESORDEN, LA NOCHES PICOTEA MUCHO\n",
    "DESORDEN AL COMER POR PROBLEMAS\n",
    "COMER MÁS\n",
    "CUANDO MAS HAMBRE TIENE ES POR LA MAÑANA\n",
    "MARIDO É PRESIDENTE DA CAMARA E TEM DE IR JANTAR A MUITAS FESTAS E ASSIM E SÃO SÓ COISAS BOAS : AÇORDA , DOCES , ETC . MUITO PÃO. NESTA ALTURA TAMBÉM PARTOU AS CAMINHADAS O QUE NÃO AJUDOU TAMBÉM.\n",
    "picoteo\n",
    "DESCONTROL DE LAS COMIDAS\n",
    "COME MUCHO EL FIN DE SEMANA\n",
    "NO CAMBIO DE HABITOS, COMER LO Q LE GUSTA\n",
    "PICOTEO\n",
    "MALA ALIMENTACION\n",
    "Malos habitos alimentarios\n",
    "COME 1 VEZ AL DIA\n",
    "LE  GUSTA COMER\n",
    "SIEMPRE HA COMIDO MUCHO\n",
    "Comer mal\n",
    "Dos comidas al día solamente\n",
    "mala alimentación\n",
    "ansiedad por comer , come mucha cantidad\n",
    "Malos hábitos alimentarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General lifestyle habits or circumstances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUARENTENA\n",
    "DEPOIS DA PANDEMIA COMEÇOU A AUMENTAR PESO GRADUALMENTE. SEDENTARISMO.\n",
    "PANDEMIA\n",
    "Pandemia no se ha cuidado \n",
    "Pandemia\n",
    "PANDEMIA, STRESS, SEDENTARISMO\n",
    "\n",
    "TRABAJA EN ESTACION DE SKI\n",
    "desorden horario, come mas por las noches durante el dia se restringe\n",
    "ESTA DE BAJA\n",
    "MUITO TRABALHO E REALMENTE EM EXCESSO. DEPOIS AO FINAL DA NOITE SÓ LHE APETECE \"PORCARIA\" E COME UM \"MIMINHO\"\n",
    "\n",
    "No cuidarse, la vida social \n",
    "VERANO\n",
    "COMENTA QUE SE SALE DE LA RUTINA\n",
    "le cuesta el mantenimiento, vuelve a habitos anteriores\n",
    "HIZO PRONOKAL PARA TTO DE FERTILIDAD , Y NO HA HECHO MANTENIMIENTO\n",
    "malos hábitos\n",
    "Malos hábitos.\n",
    "ESTILO DE VIDA, MALOS HÁBITOS, DIVORCIO + CAMBIO RESIDENCIA\n",
    "\n",
    "DEJO DE FUMAR Y COGIÓ PESO DES E ENTONCES.\n",
    "Deja de fumar\n",
    "\n",
    "A CAUSA DEL TRABAJO, COORDINADORA DE MERCADONA\n",
    "SE HA DEJADO Y DESCUIDADO, DEJÓ DE FUMAR HACE UN PAR DE AÑOS\n",
    "CONFINAMENTO E COM A IDADE NOTA QUE TEM MAIS DIFICULDADE EM EMAGRECER. NO FINAL DIZ QUE TAMBÉM É DO COMODISMO\n",
    "HACE 15 AÑOS HIZO LA DIETA\n",
    "FIN DE SEMANA - VIDA SOCIAL\n",
    "ha estado haciendo erasmus en italia. \n",
    "Por el verano\n",
    "SEDENTARISMO, DESORDEN HORARIO\n",
    "Le cuesta mantener el peso. \n",
    "DEJO DE FUMAR\n",
    "POCO A POCO A PARTIR DE LOS 40 AÑOS\n",
    "Los años \n",
    "VERANO + COVID\n",
    "HABITOS EN GENERAL. CONFINAMIENTO, ESTILO DE VIDA, MENOPAUSIA \n",
    "JUBILADA EN LA PANDEMIA Y AUMENTO MUCHO PESO\n",
    "DIZ QUE TEM GORDURA CONCENTRADA NO ABDOMEN E COSTAS.\n",
    "TEM METABOLISMO LENTO\n",
    "HA IDO AUMENTANDO PROGRESIVAMENTE DE MANERA ANUAL. VIAJA MUCHO. LLEGA A LA CENA CON  MUCHA ANSIEDAD\n",
    "Toda la vida ha ido subiendo y bajando\n",
    "Dejar de fumar\n",
    "MALOS HABITOS \n",
    "OBJ PASO 1 15KG\n",
    "A PARTIR DE COVID GANÓ PASO Y A PERDIDO DISCIPLINA\n",
    "ENGORDOU HÁ CERCA DE 5 ANOS. DEIXOU DE FUMAR. ENTRETANTO CASOU E QUERIA MOSTRAR OS DOTES ALIMENTARES AO MARIDO. REFERE QUE O IRMÃO APARECEU MORTO E ISSO ABALOU-A MUITO. REFERE QUE PASSOU MUITA FOME QUANDO ERA PEQUENA E AGORA NOTA QUE NÃO TEM CONTROLO NA COMIDA PORQUE ENQUANTO TIVER COMIDA COME\n",
    "SE HA DESCUIDADO Y HA SUBIDO 15Kg APROX. \n",
    "FALTA DE ROTINAS \n",
    "PROGRESIVO, IR DEJANDOSE CON EL PASO DEL TIEMPO\n",
    "Hace años estaba obesa, hizo Naturhouse y perdio mucho peso pero ahora, desde hace un año, ha empezado a subir y aunque coma bien, no para de subir\n",
    "Dejar de fumar\n",
    "Malos hábitos\n",
    "TODA LA VIDA, EXFUMADORA \n",
    "Dejar de fumar\n",
    "Evolución del día a día \n",
    "Poco a poco ha aumentado de peso\n",
    "Varias causas, deja de fumar, se casa, trabaja en eventos y teletrabajo\n",
    "DESDE OS 27 ANOS NOTOU QUE COMEÇOU A GANHAR 1KG POR ANO MAS ACHA QUE AGORA ULTIMAMENTE CHEGAR AOS 85KG FOI MAIS RÁPIDO\n",
    "Recupera peso en verano y luego le cuesta bajarlo \n",
    "ACHA QUE ESTE AUMENTO DE PESO FOI AUMENTO DE MM\n",
    "Vuelta a los antiguos hábitos\n",
    "REFERE QUE ATÉ MANTEVE O PESO MAS DEPOIS DESCONTROLOU-SE COM OS FILHOS SAIREM DE CASA PARA IR PARA FACULDADE E COM FÉRIAS E MUDANÇA DE TRABALHO\n",
    "Deja de fumar \n",
    "REFERE QUE HÁ 2 MESES ESTAGNOU NO PESO E QUE DEIXOU DE EMAGRECER\n",
    "La hace o perfecto o nada en lo absoluto.  \n",
    "DESAJUSTE HORARIO\n",
    "siempre ha tenido tendencia a subir de peso\n",
    "LA HIZO HACE UNOS 12 AÑOS\n",
    "EN POCO TIEMPO\n",
    "No hay cambios en su vida no hay motivos \n",
    "EDAD\n",
    "TODO UN POCO\n",
    "OBJETIVO: TALLA 42-44\n",
    "NUNCA HA SIDO DELGADA\n",
    "cambio en el estilo de vida \n",
    "EDAD\n",
    "PANDEMIA UNICAMENTE, UN POCO MÁS DE ANSIEDAD\n",
    "Mucha vida social y ansiedad\n",
    "Cambio de rutina por el trabajo\n",
    "AUMENTO PRGRASIVO DESDE LA PANDEMIA\n",
    "Siempre sobrepeso\n",
    "Viaja mucho\n",
    "Malos hábitos\n",
    "ATIVIDADE LABORAL - PROFESSOR UNIVERSITÁRIO - NÃO RESPEITA MUITO OS HORÁRIOS DE REFEIÇÕES E CUIDADO ALIMENTAR + ALCOOL AO JANTAR\n",
    "Muchas horas delante del PC\n",
    "PESO HABITUAL RONDA OS 89-90KG. NOS ULTIMOS 6 MESES AUMENTOU CERCA DE 10KG. DIZ-ME TER PESO IO-IO. FAZ MUITAS DIETAS MAS PERDE-SE PELO MEIO. DEPOIS DE FAZER PRONOKAL TEVE 2 FILHOS E NUNCA MAIS RECUPEROU O PESO.\n",
    "CAMBIO DE TRABAJO, PANDEMIA. COME POR ABURRIMIENTO. COME DESORDENADO\n",
    "vida social muy ajetreada\n",
    "HACE 7 AÑOS LE SOBRABAN 10KG, Y DESPUES POCO A POCO HA IDO PONIENDO PESO\n",
    "COVID, ANSEIDAD Y FALTA DE MOVILIDAD\n",
    "DESPUES DE CONFINAMIENTO, CAMBIO DE HABITOS, DEJÓ DE TRABAJAR\n",
    "Confinamiento\n",
    "VIDA SOCIAL\n",
    "DEJAR DE FUMAR HACE 2.5 AÑOS\n",
    "ESTEVE DE FÉRIAS E ATÉ FICOU COM O MESMO PESO QUE TINHA ANTES DE IR DE FÉRIAS MAS A DRA. RECOMENDOU FAZER 1 SEMANA DE P1 E DEPOIS PASSA AO P2 PARA VER SE PERDE MAIS UM POUCO\n",
    "HACE 2 TOMAS AL DIA - HORARIOS DIVERSOS - AZAFATAS VUELO\n",
    "EDAD, TRABAJO SEDENTARIO (12H SENTADA)\n",
    "TENDENCIA NATURAL\n",
    "Deja de fumar y está lesionado\n",
    "STODA LA VIDA CON SOBREPESO, COMER\n",
    "PESO HABITUAL RONDAVA OS 65KG, COMEÇOU A GANHAR PESO NA ALTURA DA PANDEMIA. TAMBÉM DEIXOU DE FUMAR NESTA ALTURA. ELEVADA INGESTÃO DE PRODUTOS AÇUCARADOS. HISTÓRICO MARCADO DE DIETAS IO-IO.\n",
    "MUCHO DESORDEN\n",
    "CAMBIO DE HÁBITOS DURANTE LOS ULTIMOS 5 AÑOS + SOCIABILIZACION\n",
    "TIENEN MUCHA VIDA SOCIAL TOMA CERVEZA Y MARTINI, \n",
    "Tendencia a coger peso\n",
    "Dejar de fumar\n",
    "Siempre ha sido \"gordita\"\n",
    "Malos hábitos\n",
    "EM OUT/2022 INICIOU ACOMPANHAMENTO POR NUTRICIONISTA NA CUF (PESO INICIAL 120KG), PERDENDO ATÉ AGORA CERCA DE 9KG. O PESO HABITUAL MAIS RECENTE RONDAVA OS 120KG. DESDE OS 17 ANOS QUE NÃO PESA QUE MENOS QUE 100KG.\n",
    "PESO HABITUAL RONDA OS 78KG COMEÇOU A AUMENTAR PESO DE HÁ 1 ANO PARA AGORA. DESLEIXO ALIMENTAR. JÁ PERDEU 4KG NO ULTIMO MÊS COM CUIDADOS ALIMENTARES PRÓPRIOS.\n",
    "MUDANÇA P SUIÇA E AUMENTO DE 16KG NUM ANO. TB TEVE BURNOUT QUANDO COMEÇOU A AUMENTAR EM 2021. DEIXOU TABACO EM 2020 E TB ASSOCIA UM POUCO A ISSO O AUMENTO DE PESO. DOCES\n",
    "HIZO LA DIETA HACE 10 AÑOS\n",
    "TODA SU VIDA HA TENIDO SOBREPESO. \n",
    "MALOS HÁBITOS\n",
    "TRABAJO MAS SEDENTARIO, ANSIEDAD\n",
    "HIZO LA DIETA HACE MUCHOS AÑOS\n",
    "SIEMPRE SOBREPESO, HACE 2 AÑOS DUELO, LA ECHARON DEL TRABAJO\n",
    "COVID \n",
    "PAULATINO, CADA AÑO IBA SUBIENDO DE PESO\n",
    "PESO HABITUAL RONDAVA OS 65-68KG, DEPOIS DE SER MÃE (HÁ 11 ANOS) ESTABILIZOU NOS 70KG; NÃO ATRIBUI NENHUMA CAUSA AO EXCESSO DO PESO, DIZ QUE SEMPRE FOI MAGRA E TEVE PERCENTIL ABAIXO DO PESO EM CRIANÇA.\n",
    "ACHA QUE TEM ALGUMA CARGA GENÉTICA PARA TER MAIS PESO PORQUE O PAI ERA OBESO E DIABETICO TIPO 1. SEMPRE TEVE CUIDADO COM DOCES. AGORA DESDE O INICIO DA PANDEMIA QUE ESTÁ MAIS PARADA E NOTA QUE ANTES CONSEGUIA EMAGRECER E MANTÊ-LO E ULTIMAMENTE NÃO CONSEGUE PERDER E MUITO MENOS MANTER\n",
    "VIAJA MUCHO, SEDENTARISMO, JETLAG\n",
    "DEJAR DE FUMAR\n",
    "AUMENTO DE PESO LENTO Y GRADUAL\n",
    "AUMENTO MUY PROGRESIVO DESDE HACE 2 AÑOS \n",
    "PESO ACIMA DOS 70KG JÁ HÁ UNS 3 ANOS PESO HABITUAL 68-69KG.\n",
    "METABOLISMO LENTO + OBSTIPADA + SEDENTÁRIA + É PREGUIÇOSA A BEBER ÁGUA\n",
    "Medico que trabaja en urgencias y sus horarios son indefinidos \n",
    "NÃO FAZ IDEIA. DIZ QUE JÁ É DOUTORADA EM DIETAS E O PROBLEMA É O IO IO CONSTANTE DE PESO. VAI FAZER ANALISES PARA PERCEBER O QUE SE PASSA MAS JÁ SABE QUE TEM UM QUISTO NA TIROIDE, TRABALHO MUITO SEDENTÁRIO. \n",
    "DESDE LOS 12 AÑOS HA TENIDO PROBLEMAS DE PESO.\n",
    "NÃO QUIS TRAÇAR OBJETIVOS QUE NÃO CONSEGUE CUMPRIR. QUER IR FAZENDO O TTO SEM EXPECTATIVAS CONCRETAS DE PERDA.\n",
    "PESO HABITUAL TEM RONDADO O PESO ATUAL PESO MINIMO EM IDADE ADULTA 90KG PESO HABITUAL 86KG PESO MÁXIMO=118KG ELLA QUIERE LLEGAR A 54KG\n",
    "AUMENTO PROGRESIVO, DESORGANIZACION\n",
    "MALOS HÁBITOS, HORARIOS\n",
    "SE MANTUVO BIEN HASTA EL 2021\n",
    "PORQUE CUANDO SE DEJA, NO SABE PARAR. \n",
    "come segun ella bien, se siente saciada\n",
    "Sobrepeso toda la vida. \n",
    "INICIOU DIETA NO ANO PASSADO POR AUTO RECREAÇÃO PERDENDO JÁ 24KG QUE NÃO VOLTOU A RECUPERAR. GOSTAVA DE PERDER MAIS 30KG.\n",
    "TRABALHA ENTRE 10-12H/DIA.\n",
    "DESDE LA IQ\n",
    "TRABAJA DESDE 6.30H A 19.30H!!!!\n",
    "CONFINAMIENTO - COGIÓ 17 KG\n",
    "NUNCA HA PESADO TANTO COMO AHORA\n",
    "CAMBIO DE PAREJA, \n",
    "POR LA PANDEMIA, ANTES IBA AL GYM\n",
    "PESO HABITUAL 76-80KG PESO MÁXIMO 80KG PESO MIN 60KG \n",
    "DESCONTROLO HORÁRIO E CANSAÇO. FALTA DE DESCANSO IMPULSIONA MAUS HÁBITOS ALIMENTARES.\n",
    "ES MADRE SOLTERA DE 2 NIÑOS DE 6 AÑOS\n",
    "Nunca ha estado en el peso ideal \n",
    "PANDEMIA COM AUMENTO DO SEDENTARISMO\n",
    "PESO MÁXIMO EM IDADE ADULTA 82KG (MUITO RECENTEMENTE ANTES DE INICIAR ACOMPANHAMENTO DE NUTRICIONISTA) PESO HABITUAL RONDA 68-70KG COMEÇOU A AUMENTAR DE PESO GRADUALMENTE DESDE HÁ 3 ANOS ATRÁS. DESIQUILIBRIO ALIMENTAR. DEFICIENTE FRACIONAMENTO ALIMENTAR.\n",
    "SEMPRE TEVE EXCESSO DE PESO\n",
    "PESO MINIMO EM IDADE ADULTA 70KGS. ALTERAÇÕES DE ROTINA, MUDANÇAS DE TRABALHO.\n",
    "NO MANTENIMIENTO, DEJAR DE FUMAR HACE 2 AÑOS\n",
    "NÃO FAZ IDEIA. FOI UM AUMENTO DE PESO GRADUAL DESDE OS 18 ANOS\n",
    "PESO HABITUAL 64-65KG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vague/can't tell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JÁ FEZ LEV, DIETA 3 PASSOS, HERBALIFE, SEM RESULTADOS A MEDIO-LONGO PRAZO.\n",
    "ESTAVA ACOMPANHADA (TRABALHO), ACHEI QUE NÃO ESTAVA CONFORTÁVEL NA PORMENORIZAÇÃO DESTE TEMA E NÃO O EXPLOREI MAIS.\n",
    "PROGRESIVO\n",
    "OBJ: SALUD\n",
    "UN POCO TODO\n",
    "DESCONTROL GENERAL Y MUCHOS FACTORES\n",
    "SAUDÁVEL.\n",
    "COMPROMISOS\n",
    "No sabe decirme\n",
    "NÃO SABE MESMO PORQUE DIZ QUE ATÉ TEM CUIDADOS ALIMENTARES MAS A DRA. FEZ ANÁLISES A NIVEL ENDÓCRINO ESTÁ TUDO BEM\n",
    "NÃO SABE DIZER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *PAST*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Today's results: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basically no relevant association between any variables and outcomes and any of the behavioral scores - just a few significant associations, that don't show a common pattern at all\n",
    "- this may be a sign to ditch it - or to move on to standardizing the reasons of weight gain, or to look at genomics, or something. Not sure what the paper's target could be now!\n",
    "- could it make any sense to look at other, for example, competing risks models for now? \n",
    "- we have over 500 nonstandardized causes of weight gain - could we actually look at that? \n",
    "\n",
    "\n",
    "[**problems for future self**:] how to communicate this and where to lead the project now. Should\n",
    "- make sure the output is at least semisolid, don't present BS\n",
    "- have a quick go at standardizing the causes list with AI, at least at a brainstorm level\n",
    "- have to restore copilot..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population stratification, comparative statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine how to stratify the population, and what exact variables to compare between strata. The table should have the variables of interest as rows, and the different strata/group markers as columns. \n",
    "\n",
    "promt\n",
    "-revise, ideas\n",
    "-discuss tests of 3\n",
    "-generate code w principles, name comparative_summary\n",
    "\n",
    "ROWS, variables to compare between strata: \n",
    "- N: N (%) of subjects in strata and proportion of whole population\n",
    "- age: mean (sd) age\n",
    "- sex_f: n (%) number and proportion of women\n",
    "- height: mean (sd)\n",
    "- baseline_weight_kg: mean (sd)\n",
    "- baseline_bmi: mean (sd)\n",
    "- hunger_y: N (%) of 1 (true) values\n",
    "- satiety_y: N (%) of 1 (true) values\n",
    "- emotional_eating_y: N (%) of 1 (true) values\n",
    "- emotional_eating_value_likert: mean (sd)\n",
    "- quantity_control_likert: mean (sd)\n",
    "- impulse_control_likert: mean (sd)\n",
    "- total_followup_days: mean (sd)\n",
    "- avg_days_between_measurements: mean (sd)\n",
    "- genomics_sample_id: N (%)\n",
    "- total_wl_%: mean (sd)\n",
    "- bmi_reduction: mean (sd)\n",
    "- instant_dropout: N (%) of those where total_followup_days = 1\n",
    "- 40day_dropout: N (%)\n",
    "- wl_40d_%: mean (sd)\n",
    "- 60day_dropout: N(%)\n",
    "- wl_60d_%: mean (sd)\n",
    "- 80day_dropout: N (%)\n",
    "- wl_80d_%: mean (sd)\n",
    "- 5%_wl_achieved: N (%)\n",
    "- days_to_5%_wl: mean (sd)\n",
    "- 10%_wl_achieved: N (%)\n",
    "- days_to_10%_wl: mean (sd)\n",
    "- 15%_wl_achieved: N (%)\n",
    "- days_to_15%_wl: mean (sd)\n",
    "\n",
    "\n",
    "COLUMNS, strata of interest: \n",
    "*p-values: each stratification criterion should generate 3 columns: strata 1, strata 2, p-value*\n",
    "- age: < / >= median\n",
    "- sex_f: 0 for male, 1 for female\n",
    "- height: < / >= median\n",
    "- baseline_weight_kg: < / >= median\n",
    "- baseline_bmi: < / >= 30 (the limit between overweight and obesity, also happens to be the median)\n",
    "- total_wl_%: < / >= median\n",
    "- bmi_reduction: < / >= median\n",
    "- hunger_yn: yes / no\n",
    "- satiety_yn: yes / no\n",
    "- emotional_eating_yn: yes / no\n",
    "- emotional_eating_value_likert: < / >= median\n",
    "- quantity_control_likert: < / >= median\n",
    "- impulse_control_likert: < / >= median\n",
    "- total_followup_days: <=10 / >10 \n",
    "- avg_days_between_measurements: < / >= median\n",
    "- genomics_sample_id: available / NA\n",
    "*would be nice to keep the following variables dynamic, fetching the values directly from the table OR defining in config, in case I'd want to create different scenarios too* \n",
    "- 40day_dropout: yes / no\n",
    "- 60day_dropout: yes / no\n",
    "- 80day_dropout: yes / no\n",
    "- 5%_wl_achieved: yes / no\n",
    "- 10%_wl_achieved: yes / no\n",
    "- 15%_wl_achieved: yes / no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases for comparative statistical tests: \n",
    "\n",
    "\n",
    "Why Welch's t-test and Justification:\n",
    "\n",
    "What it is: Welch's t-test is a variation of the standard independent samples t-test used to compare the means of two independent groups.\n",
    "Key Difference: Unlike the standard Student's t-test, Welch's t-test does not assume that the two groups have equal variances. Student's t-test requires this assumption (homoscedasticity).\n",
    "Why Recommend/Justify: In real-world data, especially clinical or observational data, it's often unrealistic to assume that different groups (e.g., high vs. low emotional eaters) will have the exact same variance (spread) for a given continuous variable (like baseline_bmi or total_wl_%). Welch's t-test adjusts its calculation (specifically, the degrees of freedom) to account for potential differences in variances.\n",
    "Justification: \"We chose Welch's t-test for comparing continuous variables between strata because it does not assume equal variances across groups. This makes the test more robust and reliable when analyzing real-world data where the variance might differ between the compared groups, providing a more accurate p-value without needing a preliminary test for variance equality.\" It's generally considered a safer default than Student's t-test unless you have strong evidence that variances are indeed equal.\n",
    "Expected Cell Count and Fisher's Exact Test:\n",
    "\n",
    "Context: This applies when comparing two categorical variables using a contingency table (e.g., a 2x2 table for emotional_eating_yn vs. 10%_wl_achieved).\n",
    "Observed vs. Expected Counts:\n",
    "Observed Count: The actual number of individuals falling into a specific cell of the table (e.g., the number of people who are emotional eaters AND did achieve 10% WL).\n",
    "Expected Count: The number of individuals you would expect to fall into that cell if the two variables were completely independent (i.e., if emotional eating had absolutely no association with achieving 10% WL). It's calculated for each cell based on the row and column totals: Expected Count = (Row Total * Column Total) / Grand Total.\n",
    "Chi-squared Test Assumption: The Chi-squared (χ²) test compares the observed counts to these expected counts. However, the statistical validity of the Chi-squared test relies on an approximation that works well only when the expected counts are sufficiently large.\n",
    "The Case for Fisher's Exact Test: Fisher's Exact Test is used when the assumption for the Chi-squared test is violated due to low expected cell counts.\n",
    "Rule of Thumb: The most common guideline is to use Fisher's Exact Test if any cell in the contingency table has an expected count less than 5. Some sources might say if >20% of cells have expected counts < 5.\n",
    "Why? When expected counts are small, the Chi-squared approximation becomes inaccurate. Fisher's test calculates the exact probability of observing the actual table results (or more extreme results) given the fixed row and column totals, without relying on the approximation.\n",
    "For 2x2 Tables: Because it calculates an exact probability and is computationally feasible for 2x2 tables, Fisher's Exact Test is often preferred for any 2x2 table analysis, especially when sample sizes are small or distributions are highly skewed, even if all expected counts are technically >= 5. It's considered more conservative and accurate in these situations.\n",
    "In summary: Use Welch's t-test for continuous variables unless you're sure variances are equal. Use Fisher's Exact Test for categorical variables (especially 2x2 tables) if any expected cell count is less than 5, or often as a default for 2x2 tables due to its exact nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cox prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[9.05] prompting for Cox module\n",
    "\n",
    "I know it is not good practice to want to start with designing a Cox regression pipeline, and I still want to do it. It is true that Cox PH is somewhat of an advanced models, and simpler statistical tests early on whould inform much more about the actual distribution of the data, and get me better suited for continuing on. The reason why I want to start with 'the hard thing' is to have a peak at some of what waits down the pipeline. It would for the one part be good to see if these draft models show any interesting results in my data, and also, it would be nice to familiarize myself with the challenges that lie ahead. By any means, pipeline design is still brainstorming, as to run it, I need to go back upstream the notebook to tackle the conversion of categorical variables to bools. \n",
    "\n",
    "This is a rough pipeline draft I was thinking of: \n",
    "\n",
    "CONFIG: \n",
    "- input and output file names and paths #depending on the analysis scenario\n",
    "- target: specify - #% of weight loss, or last measurement (to study followup length/dropout)\n",
    "- window: specify - #the range of followup time for each scenario\n",
    "- predictor: specify - #the emotional eating variable in question for a given scenario\n",
    "- covariates: specify - #variables like age, sex, baseline weight and BMI, frequency of measurements that the model is adjusted for in each scenario - or even unadjusted models can be ran where this is blank\n",
    "HELPERS\n",
    "- data loading and quality check\n",
    "- any similar function that might be necessary\n",
    "COX REGRESSION\n",
    "- function to calculate proportional hazards for each scenario\n",
    "- probably should include a function to check whether model assumptions hold in the given scenario - or that should be ran irrespective of the given scenario? \n",
    "ORCHESTRATE\n",
    "- call all the defined functions on the data\n",
    "EXEC\n",
    "- run the analysis loop\n",
    "- save the output, ideally in the same SQL database - but also, a folder tree where scenario-assumption plotting pairs can be stored could also work\n",
    "\n",
    "\n",
    "This pipeline could run the same analysis for a number of different scenarios - different event, different window, different predictor, adjustment/nonadjustment. As a first glance, how does this idea sound to you? \n",
    "\n",
    "\n",
    "RESPONSE \n",
    "\n",
    "Okay, I understand your reasoning for wanting to tackle the Cox regression part first as an exploratory step. Getting a feel for the modeling process and potential assumption issues early can definitely inform the rest of your analysis and help manage expectations.\n",
    "\n",
    "Let's refine the pipeline structure specifically for running and evaluating Cox models based on your sa_input_table.\n",
    "\n",
    "Refined Cox Regression Pipeline Structure:\n",
    "\n",
    "CONFIG:\n",
    "\n",
    "DB_PATH: Path to your survival_analysis.sqlite database.\n",
    "INPUT_TABLE_NAME: \"sa_input_table\"\n",
    "OUTPUT_TABLE_NAME: \"cox_results\" (or similar, for storing model summaries)\n",
    "ASSUMPTION_PLOT_DIR: Folder path to save PH assumption plots.\n",
    "SCENARIOS: A list of dictionaries, where each dictionary defines a specific analysis run. This makes it easy to loop through.\n",
    "HELPERS:\n",
    "\n",
    "load_data(db_path, table_name): Loads the sa_input_table.\n",
    "preprocess_data(df): Handles final prep needed specifically for Cox:\n",
    "Ensure categorical predictors/covariates like sex, hunger, satiety, emotional_eating are numerically encoded (e.g., 0/1). This is where you'd implement the conversion if not done upstream.\n",
    "Handle any remaining missing values in the columns needed for the models (e.g., using listwise deletion for simplicity initially, df.dropna(subset=columns_for_model)).\n",
    "Maybe create median split flags here if you want to run models stratified by them (though using continuous is often preferred in Cox).\n",
    "COX REGRESSION MODULE:\n",
    "\n",
    "run_cox_model(df, duration_col, event_col, predictor_cols, scenario_name, plot_dir):\n",
    "Input: DataFrame subset with necessary columns, duration column name, event column name, list of predictor/covariate column names, scenario name (for plot saving), plot directory.\n",
    "Actions:\n",
    "Instantiate CoxPHFitter from lifelines.\n",
    "Fit the model: cph.fit(df, duration_col=duration_col, event_col=event_col, formula=\" + \".join(predictor_cols)) (using formula is often cleaner).\n",
    "Check Proportional Hazards Assumption:\n",
    "Call cph.check_assumptions(df, show_plots=False, p_value_threshold=0.05). This returns results and can optionally plot.\n",
    "Save assumption check summary (p-values).\n",
    "Optionally, generate and save Schoenfeld residual plots for key variables: cph.plot_covariate_groups(...) or manually plot residuals over time. Save plots to plot_dir using scenario_name.\n",
    "Extract results: cph.summary (Hazard Ratios, CIs, p-values), concordance index (cph.concordance_index_), assumption check results.\n",
    "Output: A dictionary containing the model summary (as DataFrame/dict), concordance index, and assumption check results.\n",
    "ORCHESTRATION & EXECUTION:\n",
    "\n",
    "Load data using load_data.\n",
    "Preprocess data using preprocess_data.\n",
    "Initialize an empty list all_results.\n",
    "Loop through each scenario in SCENARIOS:\n",
    "Print which scenario is running.\n",
    "Determine duration_col and event_col based on scenario['event_type']:\n",
    "If event_type == 'target':\n",
    "duration_col = f\"days_to_{scenario['target_perc']}_perc_wl\"\n",
    "event_col = f\"{scenario['target_perc']}_perc_wl_achieved\" (ensure this is 0/1 or bool)\n",
    "If event_type == 'dropout':\n",
    "duration_col = 'total_followup_days' (or specific window like days_to_60d_measurement if appropriate)\n",
    "event_col = f\"{scenario['time_window']}d_dropout\" (ensure this is 0/1 or bool)\n",
    "Define predictor_cols = scenario['predictors'] + scenario['covariates'].\n",
    "Select relevant columns and handle missing data for this specific model: df_model = df_analysis[ [duration_col, event_col] + predictor_cols ].dropna()\n",
    "Check if df_model is empty after dropping NAs. If so, skip.\n",
    "Call run_cox_model with the appropriate arguments.\n",
    "Store the returned results dictionary, adding the scenario_name to it. Append to all_results.\n",
    "Save Results:\n",
    "Convert all_results (list of dicts, where each dict contains model summary etc.) into a structured format. Saving the cph.summary DataFrame directly might be tricky if combining results. A better approach might be to extract key info (variable, HR, CI_lower, CI_upper, p-value, concordance, assumption_p_value) for each scenario into a new summary DataFrame.\n",
    "Connect to the SQLite DB and save this summary DataFrame to the OUTPUT_TABLE_NAME (e.g., cox_results), perhaps using df.to_sql(..., if_exists='append').\n",
    "Key Considerations:\n",
    "\n",
    "Assumption Checking: Yes, the PH assumption needs to be checked for each model you fit, as it depends on the specific covariates included. lifelines makes this relatively easy. If the assumption is violated for a key predictor:\n",
    "Report it as a limitation.\n",
    "Consider stratification (if the violation is due to a categorical variable).\n",
    "Consider time-varying covariates/coefficients (more advanced).\n",
    "Consider alternative models (like accelerated failure time models).\n",
    "Data Types: Ensure your duration columns are numeric (days) and event columns are boolean or 0/1. Categorical predictors must be numerically encoded (dummy variables or 0/1).\n",
    "Interpretation: Focus on the Hazard Ratios (HRs) and their confidence intervals. An HR > 1 means increased hazard (faster event rate), HR < 1 means decreased hazard (slower event rate) for a one-unit increase in the predictor, holding others constant.\n",
    "Saving Output: Saving key summary stats (HR, CI, p-value per variable per model) to a single SQL table is efficient for later aggregation and comparison. Saving plots separately is necessary.\n",
    "This structure provides a modular way to run your exploratory Cox models, check assumptions systematically, and store the results. Remember to handle the upstream data type conversions (like sex to numeric) either in the sa_input_table creation or in the preprocess_data helper function here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[19.55] pipeline\n",
    "\n",
    "Text-Based Analysis Tree/Modules:\n",
    "\n",
    "Module 1: Setup & Preparation\n",
    "\n",
    "Input: sa_input_table (from SQLite).\n",
    "Actions:\n",
    "Load data into pandas DataFrame.\n",
    "Perform final checks/cleaning (e.g., confirm data types, handle any unexpected missing values if age fix isn't upstream yet).\n",
    "Define analysis parameters (lists of time windows, targets, predictors, covariates).\n",
    "Create Stratification Variables:\n",
    "Calculate medians for numeric predictors (emotional_eating_value, quantity_control, impulse_control) based on the analysis sample.\n",
    "Create new binary columns based on median splits (e.g., emotional_eating_high = 1 if value >= median else 0).\n",
    "Create binary columns for baseline characteristics if needed (e.g., obesity_class_II_plus, age_above_median).\n",
    "Output: A prepared DataFrame (df_analysis) ready for analysis, containing original data plus the new stratification columns.\n",
    "Module 2: Descriptive Statistics\n",
    "\n",
    "Input: df_analysis.\n",
    "Actions:\n",
    "Calculate overall descriptive statistics (N, mean/SD for continuous, N/% for categorical) for baseline characteristics, eating behaviors, and key outcome variables (across different timepoints/targets).\n",
    "Generate Stratified Descriptive Tables: Create tables comparing baseline characteristics and outcomes between groups defined by:\n",
    "Key demographics (e.g., Sex, Age group, BMI group).\n",
    "Each eating behavior variable (using the boolean versions and the median-split versions).\n",
    "Output: Summary tables (e.g., pandas DataFrames, formatted text/markdown) presenting the cohort description overall and by subgroups.\n",
    "Module 3: Fixed-Timepoint Analysis (RQ1 & RQ2)\n",
    "\n",
    "Input: df_analysis, analysis parameters (time window, target %).\n",
    "Actions (within a loop for each scenario):\n",
    "Bivariate Tests: Perform t-tests/correlations comparing eating behaviors with wl_Xd_%. Perform chi-square tests comparing eating behaviors with X%_achieved.\n",
    "Linear Regression (RQ1): Model wl_Xd_% using eating behaviors + covariates.\n",
    "Logistic Regression (RQ2): Model X%_achieved using eating behaviors + covariates.\n",
    "Output: Stored results (test statistics, p-values, regression coefficients/ORs, confidence intervals, model summaries) for each scenario.\n",
    "Module 4: Time-to-Event Analysis (RQ3 & RQ4)\n",
    "\n",
    "Input: df_analysis, analysis parameters (time window, target %).\n",
    "Actions (within a loop for each scenario):\n",
    "Kaplan-Meier Analysis: Generate KM plots and log-rank tests for time-to-target and time-to-dropout, stratified by key eating behavior variables.\n",
    "Cox Regression (RQ3): Model time-to-target (days_to_X%_wl, X%_achieved) using eating behaviors + covariates. Check assumptions.\n",
    "Cox Regression (RQ4): Model time-to-dropout (total_followup_days, Xd_dropout) using eating behaviors + covariates. Check assumptions.\n",
    "(Optional Later): Competing Risks Models.\n",
    "Output: Stored results (log-rank p-values, hazard ratios, confidence intervals, assumption checks, model summaries) for each scenario. Plots saved as files or displayed.\n",
    "Module 5: Results Aggregation & Presentation\n",
    "\n",
    "Input: Stored results from Modules 3 & 4.\n",
    "Actions:\n",
    "Combine results from different scenarios into summary tables (e.g., showing HRs for emotional_eating_value across all scenarios).\n",
    "Create visualizations summarizing key findings (e.g., forest plots of HRs).\n",
    "Format tables and plots for reporting.\n",
    "Output: Final tables and figures for the report/paper.\n",
    "Population Splits & Descriptive Table:\n",
    "\n",
    "Splits: Yes, creating descriptive tables split by sex, age group, BMI group, and individually by each of the 6 eating behavior variables (using the boolean/median split versions) is a good plan. A cumulative score could be explored later, but individual effects are clearer initially.\n",
    "Table Content: Your idea for the descriptive table is excellent. Rows could represent key metrics, and columns could show stats for different subgroups.\n",
    "Rows (Metrics):\n",
    "N (%) of subgroup\n",
    "Baseline Age (Mean, SD)\n",
    "Baseline BMI (Mean, SD)\n",
    "Baseline Sex (% Female)\n",
    "Baseline Eating Behaviors (Mean/SD or N/% as appropriate)\n",
    "total_followup_days (Mean, SD)\n",
    "% Dropout at 60d (Calculated from 60d_dropout)\n",
    "wl_60d_% (Mean, SD)\n",
    "% Achieving 10% WL by 60d (Calculated from relevant columns)\n",
    "days_to_10%_wl (Median, IQR - among those who achieved)\n",
    "(Repeat outcomes for other key timepoints/targets, e.g., 80d, 15%)\n",
    "Columns (Subgroups):\n",
    "Overall Cohort\n",
    "Male / Female\n",
    "Age <= Median / Age > Median\n",
    "BMI < 30 / BMI >= 30 (or other classes)\n",
    "Hunger No / Hunger Yes\n",
    "Satiety No / Satiety Yes\n",
    "Emotional Eating No / Emotional Eating Yes\n",
    "Emotional Eating Value < Mdn / >= Mdn\n",
    "Quantity Control < Mdn / >= Mdn\n",
    "Impulse Control < Mdn / >= Mdn This provides a comprehensive overview (\"Table 1\" typically).\n",
    "Regression Model Recap:\n",
    "\n",
    "Linear Regression: Correct. It predicts a continuous outcome (like wl_60d_%) based on predictors. It tells you, for example, \"A one-unit increase in emotional_eating_value is associated with an average change of B percent weight loss at 60 days, holding age, sex, and baseline BMI constant.\"\n",
    "Logistic Regression: Correct. It predicts a binary outcome (like 10%_wl_achieved - yes/no). It tells you, for example, \"Participants with high emotional eating (vs. low) have X times the odds of achieving 10% weight loss by 60 days, holding covariates constant.\" (Where X is the Odds Ratio).\n",
    "Cox PH Regression: Correct. It models the time until an event occurs. It analyzes the hazard rate - the instantaneous risk of the event happening at any given time, given it hasn't happened yet. It tells you, for example, \"Participants with high emotional eating have Y times the hazard rate (instantaneous risk) of achieving 10% weight loss compared to those with low emotional eating, at any point in time, holding covariates constant.\" (Where Y is the Hazard Ratio). And yes, the \"event\" can be defined as achieving the target OR as dropping out. You run separate models for each event type.\n",
    "\n",
    "\n",
    "Median Flags Creation: It's generally more flexible and statistically sound to create the median split flags downstream in your analysis script (Module 1) rather than upstream in the data creation pipeline.\n",
    "\n",
    "Reasoning: The median should ideally be calculated based on the specific sample you are actually analyzing after handling any missing data relevant to that particular analysis. If you calculate it upstream on the entire table, but then exclude some participants from a specific regression due to missing covariates, the median of the analyzed subset might differ slightly. Doing it downstream ensures the split accurately reflects the group you're modeling. It also makes it easier to experiment with different splits (median, tertiles, etc.) later without modifying the base table.\n",
    "Feasibility in One Day: Designing and running this entire pipeline (all modules, all scenarios, full interpretation, polished outputs) thoroughly in a single working day is highly ambitious and likely unrealistic.\n",
    "\n",
    "What might be feasible in one focused day:\n",
    "Setting up the analysis notebook (Module 1: loading, basic prep, creating median split variables).\n",
    "Generating the descriptive statistics (Module 2).\n",
    "Writing and running the initial code for the fixed-timepoint and survival analyses (Modules 3 & 4) for one primary scenario (e.g., 60d/10%).\n",
    "What takes longer:\n",
    "Debugging inevitable coding issues.\n",
    "Thoroughly checking model assumptions (especially for Cox).\n",
    "Iterating on models based on initial results.\n",
    "Running the analyses across all scenarios.\n",
    "Carefully interpreting the results from all models and scenarios.\n",
    "Aggregating and formatting results into publication-ready tables and figures (Module 5).\n",
    "Analysis is an iterative process. Aim to get the structure and a first set of results for one scenario done in a day, which would be excellent progress. The full exploration and refinement will take more time.\n",
    "\n",
    "\n",
    "\n",
    "[8.44] ideas to improve sa input database\n",
    "- fetch final BMI too\n",
    "- maybe fetch baseline weight and BMI from measurements, or comparatively from measurements and medical records both as a test to see if any discrepancies exist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[16.16] very nice progress today! a unified SA input dataset with 3 WL% targets and 3 time windows, genomics and weight gain causes data completed. This contains all that it needs to contain, it is ready for both regressions and survival analysis. **Very nice!**\n",
    "\n",
    "It needs good readthrough, revision, understanding and commenting, to make sure it is really research ready, as if it is, it is a BIG step forward towards actual analyses! That paper is going to be written by the 25th of May. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[8.10] what i wanted to ask copilot about which revised (excel ideation) SA input data structure should be better for me:\n",
    "\n",
    "*the table contents* \n",
    "\n",
    "OG:\n",
    "\n",
    "patient_id  medical_record_id  baseline_date  end_date  followup_period baseline_weight  fil_weight  weight_loss_kg  weight_loss_pct  10pct_achieved  dropout  sex  age  height_m  baseline_bmi  hunger  satiety  emotiol_eating  emotiol_eating_value  quantity_control  impulse_control \n",
    "str str datetime datetime nr nr nr nr nr bool bool str, could be bool nr nr nr bool bool bool nr nr nr\n",
    "pacID mrID first mes last mes as of: days from first to last mes, as of described in D first mes weight, from measurements, last mes weight, as of fil weight as of fil weight within window if target &/ followthrough not achieved gender years from medical record from medical record, I think, maybe it should be fetched together with the measurement? bool bool bool likert likert likert\n",
    "last of window but maybe just out of curiosity, as of described in D\n",
    "last recorded fetch from records as well to see if there is mismatch?\n",
    "date of first over-target\n",
    "\n",
    "ALT:\n",
    "\n",
    "pID mID baseline_date last_aval_date total_followup baseline_weight last_aval_weight total_wl_kg total_wl_% Nd_weight wl_Nd_kg wl_Nd_% Nd_date days_to_Nd_measurement Nd_dropout X%_achieved X%wl% X%_wl_date days_to_X%_wl sex  age  height_m  baseline_bmi  hunger  satiety  emotiol_eating  emotiol_eating_value  quantity_control  impulse_control \n",
    "str str datetime datetime nr nr nr nr nr nr nr nr datetime nr bool bool nr datetime nr str, could be bool nr nr nr bool bool bool nr nr nr\n",
    "pacID mrID first mes last available mes as of: days from first to last mes first mes weight last aval mes weight as of last aval mes as of last aval mes weight at N days, for example, 40 weight loss at N days weight loss at N days exact date of measurement closest to N-day window, eg. 40 exact days until N-day measurement, eg. 40 is/isn't a dropout as of N days (for example 40) X% target weight loss achieved or not, for example 5% exact WL% of first over-target measurement date of first over-target measurement days from baseline to first over-target measurement other clinical factors to consider -- >\n",
    "the absolute last one of the patient-record group, even if followup is 2y\n",
    "\n",
    "EX WIDE:\n",
    "\n",
    "pID mID baseline_date last_aval_date total_followup baseline_weight last_aval_weight total_wl_kg total_wl_% 40d_weight wl_40d_kg wl_40d_% 40d_date days_to_40d_measurement 40d_dropout 60d_weight wl_60d_kg wl_60d_% 60d_date days_to_60d_measurement 60d_dropout 80d_weight wl_80d_kg wl_80d_% 80d_date days_to_80d_measurement 80d_dropout 5%_achieved 5%wl% 5%_wl_date days_to_5%_wl 10%_achieved 10%wl% 10%_wl_date days_to_10%_wl 15%_achieved 15%wl% 15%_wl_date days_to_15%_wl sex  age  height_m  baseline_bmi  hunger  satiety  emotiol_eating  emotiol_eating_value  quantity_control  impulse_control \n",
    "example1 id1 1-Jan 31-Dec 365 100 75 25 25 90 10 10 9-Feb 40 0 80 20 20 2-Feb 59 0 75 25 25 23-Mar 82 0 1 6 20-Jan 20 1 10 9-Feb 40 1 17 19-Feb 50 m 40 1,76 32 n n y 7 8 9\n",
    "example2 id2 1-Jan 30-Jan 30 100 93 7 7 1 1 1 1 5 20-Jan 20 0 1 d 60 1,54 42 n n y 1 7 7\n",
    "\n",
    "EXS LONGS:\n",
    "\n",
    "40d5p\n",
    "pID mID baseline_date last_aval_date total_followup baseline_weight last_aval_weight total_wl_kg total_wl_% 40d_weight wl_40d_kg wl_40d_% 40d_date days_to_40d_measurement 40d_dropout 5%_achieved 5%wl% 5%_wl_date days_to_5%_wl sex  age  height_m  baseline_bmi  hunger  satiety  emotiol_eating  emotiol_eating_value  quantity_control  impulse_control \n",
    "example1 id1 1-Jan 31-Dec 365 100 75 25 25 90 10 10 9-Feb 40 0 1 6 20-Jan 20 m 40 1,76 32 n n y 7 8 9\n",
    "example2 id2 1-Jan 30-Jan 30 100 93 7 7 1 1 5 20-Jan 20 d 60 1,54 42 n n y 1 7 7\n",
    "\n",
    "40d10p\n",
    "pID mID baseline_date last_aval_date total_followup baseline_weight last_aval_weight total_wl_kg total_wl_% 40d_weight wl_40d_kg wl_40d_% 40d_date days_to_40d_measurement 40d_dropout 10%_achieved 10%wl% 10%_wl_date days_to_10%_wl sex  age  height_m  baseline_bmi  hunger  satiety  emotiol_eating  emotiol_eating_value  quantity_control  impulse_control \n",
    "example1 id1 1-Jan 31-Dec 365 100 75 25 25 90 10 10 9-Feb 40 0 1 10 9-Feb 40 m 40 1,76 32 n n y 7 8 9\n",
    "example2 id2 1-Jan 30-Jan 30 100 93 7 7 1 0 d 60 1,54 42 n n y 1 7 7\n",
    "\n",
    "40d15p\n",
    "pID mID baseline_date last_aval_date total_followup baseline_weight last_aval_weight total_wl_kg total_wl_% 40d_weight wl_40d_kg wl_40d_% 40d_date days_to_40d_measurement 40d_dropout 15%_achieved 15%wl% 15%_wl_date days_to_15%_wl sex  age  height_m  baseline_bmi  hunger  satiety  emotiol_eating  emotiol_eating_value  quantity_control  impulse_control \n",
    "example1 id1 1-Jan 31-Dec 365 100 75 25 25 90 10 10 9-Feb 40 0 1 17 19-Feb 50 m 40 1,76 32 n n y 7 8 9\n",
    "example2 id2 1-Jan 30-Jan 30 100 93 7 7 1 1 d 60 1,54 42 n n y 1 7 7\n",
    "\n",
    "60d5p\n",
    "pID mID baseline_date last_aval_date total_followup baseline_weight last_aval_weight total_wl_kg total_wl_% 60d_weight wl_60d_kg wl_60d_% 60d_date days_to_60d_measurement 60d_dropout 5%_achieved 5%wl% 5%_wl_date days_to_5%_wl sex  age  height_m  baseline_bmi  hunger  satiety  emotiol_eating  emotiol_eating_value  quantity_control  impulse_control \n",
    "example1 id1 1-Jan 31-Dec 365 100 75 25 25 80 20 20 2-Feb 59 0 1 6 20-Jan 20 m 40 1,76 32 n n y 7 8 9\n",
    "example2 id2 1-Jan 30-Jan 30 100 93 7 7 1 1 5 20-Jan 20 d 60 1,54 42 n n y 1 7 7\n",
    "\n",
    "*a description*\n",
    "\n",
    " The idea is basically including BOTH the target weight loss and time window information in the same data unit. This unit can then be structured in a long format, or can be split to wide formats in an analysis-specific way.\n",
    "\n",
    "What do you think, which format is better for achieving the 4-question-based research goal we discussed earlier?\n",
    "Additionally, is there anything missing or not ideal about this structure for that proposed research report?\n",
    "\n",
    "*an important detail*\n",
    "\n",
    "There is a subtle but important distinction - that I was not using the wide and long expressions properly. \n",
    "\n",
    "Technically, both of the proposed layouts are wide, having one row per patient. However, the first one contains all target and window case observations in the same data frame, whereas the second layout separates the distinct target-window cases into distinct tables, much like the current SQL implementations. \n",
    "\n",
    "Practically, when executing the data analysis pipeline, using one vs the other would mean subsetting a large data frame for each scenario vs. using distinct data frames for each scenario. \n",
    "\n",
    "Considering this clarification, please revise your answer on which one should be the optimal choice for my use case. \n",
    "\n",
    "Also, comment on whether I am missing something potentially important, or misleading in this structure. \n",
    "\n",
    "[17.30] **AI-gen data analysis plan for emotional values on weight loss success**\n",
    "\n",
    "Proposed Analysis: Investigating the Impact of Baseline Eating Behaviors on Weight Loss Success and Dropout\n",
    "\n",
    "1. Research Questions:\n",
    "\n",
    "RQ1: Are baseline self-reported eating behaviors (hunger, satiety, emotional eating, quantity control, impulse control) associated with the magnitude of weight loss (e.g., % weight loss) at specific time points (e.g., ~60 days, ~80 days)?\n",
    "RQ2: Do baseline self-reported eating behaviors predict the likelihood of achieving clinically significant weight loss targets (e.g., 5%, 10%, 15%) by specific time points?\n",
    "RQ3: Are baseline self-reported eating behaviors associated with the time it takes to achieve weight loss targets?\n",
    "RQ4: Do baseline self-reported eating behaviors predict the likelihood of dropping out of the program before reaching specific time points?\n",
    "2. Primary Datasets for Analysis:\n",
    "\n",
    "Use the survival analysis datasets generated (e.g., sa_40d_5p, sa_60d_10p, sa_80d_15p, etc.). These tables are ideal because they:\n",
    "Focus on the first medical record per patient (addressing the multiple interventions issue for this specific analysis).\n",
    "Contain key outcome variables calculated for survival analysis:\n",
    "followup_period (time variable)\n",
    "X%_achieved (event status for achieving target)\n",
    "dropout (event status for dropout)\n",
    "wl% (magnitude of weight loss at the end measurement)\n",
    "Include the merged baseline characteristics and eating behavior variables.\n",
    "3. Key Variables:\n",
    "\n",
    "Outcomes:\n",
    "wl% (Continuous, for RQ1)\n",
    "X%_achieved (Binary, for RQ2 - e.g., 10%_achieved)\n",
    "followup_period & X%_achieved (Time-to-event, for RQ3)\n",
    "followup_period & dropout (Time-to-event, for RQ4)\n",
    "Predictors (Baseline Eating Behaviors):\n",
    "hunger (Categorical: yes/no)\n",
    "satiety (Categorical: yes/no)\n",
    "emotional_eating (Categorical: yes/no)\n",
    "emotional_eating_value (Numeric/Ordinal)\n",
    "quantity_control (Numeric/Ordinal)\n",
    "impulse_control (Numeric/Ordinal)\n",
    "Covariates (Baseline):\n",
    "age\n",
    "sex\n",
    "baseline_bmi (or baseline_weight and height_m)\n",
    "4. Analysis Steps:\n",
    "\n",
    "(Preprocessing)\n",
    "\n",
    "Select one or more primary analysis datasets (e.g., focus on sa_60d_10p first).\n",
    "Handle missing data in predictors/covariates (e.g., listwise deletion for simplicity initially, or consider imputation if significant).\n",
    "Convert categorical 'yes'/'no' predictors to 0/1 for regression models.\n",
    "(Descriptive Statistics)\n",
    "\n",
    "Summarize baseline characteristics (age, sex, BMI) and eating behavior variables for the cohort(s).\n",
    "Report overall weight loss outcomes (mean wl%, % achieving target, % dropout) for the chosen time point(s).\n",
    "(RQ1 & RQ2 - Associations at Specific Time Points)\n",
    "\n",
    "Bivariate:\n",
    "Compare mean wl% between groups based on categorical eating behaviors (e.g., emotional_eating yes vs. no) using t-tests.\n",
    "Correlate numeric eating behavior scores (emotional_eating_value, etc.) with wl% using Pearson correlation.\n",
    "Compare the proportion achieving the target (X%_achieved) between groups based on categorical eating behaviors using Chi-square tests.\n",
    "Compare mean numeric eating behavior scores between those who achieved the target and those who didn't using t-tests.\n",
    "Multivariable Regression:\n",
    "Linear Regression: Predict wl% using eating behavior variables, adjusting for age, sex, baseline_bmi.\n",
    "Logistic Regression: Predict X%_achieved (binary outcome) using eating behavior variables, adjusting for age, sex, baseline_bmi. (Note: Define the \"non-achieved\" group carefully - typically those who completed the period without achieving the target, excluding dropouts, or model dropout separately).\n",
    "(RQ3 & RQ4 - Time-to-Event Analysis)\n",
    "\n",
    "Define Events/Censoring:\n",
    "Time-to-Target: Event = X%_achieved is True. Time = followup_period. Censoring occurs if dropout is True OR if X%_achieved is False at the end of followup_period.\n",
    "Time-to-Dropout: Event = dropout is True. Time = followup_period. Censoring occurs if dropout is False at the end of followup_period.\n",
    "Kaplan-Meier Analysis:\n",
    "Plot survival curves (e.g., probability of not achieving target over time) stratified by key eating behavior variables (e.g., emotional_eating yes/no, high/low emotional_eating_value). Compare curves using log-rank tests.\n",
    "Plot cumulative incidence curves for dropout stratified by eating behavior variables. Compare using appropriate tests (e.g., Gray's test if competing risks are considered, though simpler log-rank might suffice initially).\n",
    "Cox Proportional Hazards Regression:\n",
    "Model 1: Hazard of achieving target. Predictors: Eating behavior variables + covariates. Report Hazard Ratios (HR).\n",
    "Model 2: Hazard of dropout. Predictors: Eating behavior variables + covariates. Report Hazard Ratios (HR).\n",
    "5. Interpretation & Next Steps:\n",
    "\n",
    "Summarize which, if any, baseline eating behaviors are significantly associated with weight loss magnitude, likelihood of success, time-to-success, and dropout risk, after adjusting for baseline factors.\n",
    "Discuss the clinical relevance of the findings.\n",
    "Acknowledge limitations: self-report bias, specific definitions used for time windows/outcomes, focus on the first intervention only, potential unmeasured confounders.\n",
    "Suggest further analyses: exploring interactions, incorporating genetics (linking alleles_clean_pivoted), analyzing subsequent interventions (using medical_records_complete and more complex modeling).\n",
    "\n",
    "Building a solid, step-by-step analysis plan is crucial, especially when aiming for more advanced techniques later. Let's break down your recap and questions.\n",
    "\n",
    "Recap Confirmation:\n",
    "\n",
    "Yes, your understanding seems spot on. The idea is to leverage the cleaned and structured data (especially medical_records_complete, measurements_with_metadata, and the derived survival analysis datasets like sa_60d_10p, etc.) to:\n",
    "\n",
    "Describe the Cohort: Characterize the patients who have complete eating behavior data, focusing on demographics, baseline anthropometrics, and their self-reported eating behaviors.\n",
    "Explore Associations: Investigate relationships between baseline eating behavior variables (both categorical like 'emotional_eating' and continuous like 'emotional_eating_value') and weight loss outcomes.\n",
    "Survival Analysis: Model the \"time-to-event,\" where the event is achieving a specific weight loss target (e.g., 5%, 10%, 15%). This allows comparing the rate at which different groups (e.g., based on eating behavior scores or demographics) achieve success, while accounting for varying follow-up times and dropouts (censoring).\n",
    "Kaplan-Meier: Visualize survival curves for different groups (e.g., emotional eaters vs. non-eaters) and use log-rank tests to see if the curves are statistically different.\n",
    "Cox Proportional Hazards: Build regression models to identify which baseline factors (including eating behaviors, age, sex, baseline BMI, etc.) are significant predictors of hazard (instantaneous risk/rate) of achieving the weight loss target. This quantifies the impact of each factor while adjusting for others.\n",
    "Foundation for Advanced Methods: The structure created for Cox models naturally lends itself to extensions like competing risks (if dropout is considered a competing event) or survival machine learning (using algorithms like Random Survival Forests to potentially find more complex interactions or improve prediction).\n",
    "Now, for your questions:\n",
    "\n",
    "1. Time and Effort Estimation (AI-Human Collaboration):\n",
    "\n",
    "This is always tricky to estimate precisely, but here's a breakdown based on the current state and the proposed analyses:\n",
    "\n",
    "Data Already Wrangled: You've done a massive amount of the heavy lifting already. Standardizing, cleaning, linking measurements, and creating the medical_records_complete and survival_analysis.sqlite database are significant achievements. This saves a huge amount of time.\n",
    "Survival Data Preparation: The code generating the survival_analysis.sqlite database looks quite robust and handles the core logic (defining baseline, time windows, success/censoring). Minor tweaks or validation might be needed, but the foundation is there. (Effort: Low-Medium, maybe a few hours to a day for thorough validation and potential adjustments).\n",
    "Basic Survival Analysis (Kaplan-Meier, Univariate Cox): With the data prepared, generating KM curves and running simple Cox models for individual predictors is relatively straightforward using libraries like lifelines or statsmodels/scikit-survival. The AI can generate the boilerplate code quickly. The main effort will be in:\n",
    "Defining the exact groups for KM curves.\n",
    "Interpreting the output (log-rank p-values, hazard ratios, confidence intervals).\n",
    "Creating publication-quality plots.\n",
    "(Effort: Medium, likely several days of focused work, iterating with the AI, interpreting results).\n",
    "Multivariate Cox Models: Building models with multiple predictors requires more thought about variable selection, checking assumptions (proportional hazards), and interpreting adjusted hazard ratios. The AI can help with code, but the statistical thinking and interpretation are key user tasks. (Effort: Medium-High, add another few days to a week, depending on complexity and number of models).\n",
    "Advanced Analyses (Competing Risks, Survival ML): This significantly increases complexity. Data structuring might need changes, and the conceptual/statistical understanding required is higher. The AI can assist with code implementation, but the user needs to guide the process strongly. (Effort: High, could add weeks, depending on depth).\n",
    "Report Writing & Visualization: Integrating results, creating tables, and writing the narrative takes time.\n",
    "Overall Estimate: For the core survival analysis (KM, Cox) leading to an elegant first report for your supervisor, assuming the current data structure holds up well:\n",
    "\n",
    "Optimistic: If everything flows smoothly with minimal debugging and clear interpretation, perhaps 1-2 weeks of focused effort (mixing coding/analysis days).\n",
    "Realistic: Accounting for inevitable debugging, data exploration detours, refining plots, and writing, 2-4 weeks is a more likely timeframe for a polished result.\n",
    "The AI collaboration significantly speeds up the coding part, but the analysis, interpretation, and validation parts still require substantial human effort and time.\n",
    "\n",
    "2. Workflow Recommendation (Current vs. New Notebook / Agentic vs. Ask):\n",
    "\n",
    "Based on the complexity and the iterative nature of analysis:\n",
    "\n",
    "Recommendation: Use new, focused notebooks loading cleaned data, primarily using the Copilot \"Ask\" mode.\n",
    "Why New Notebooks?\n",
    "Clarity & Focus: Your current notebook is excellent for wrangling but is becoming very long. A new notebook (e.g., paper1_survival_analysis.ipynb) dedicated only to the survival analysis for this specific paper keeps things clean and manageable.\n",
    "Performance: Avoids re-running all the wrangling steps. You can directly load the necessary tables from survival_analysis.sqlite or emotional_all_notna.sqlite.\n",
    "Isolation: Reduces the risk of accidentally modifying earlier cleaning code or dealing with namespace conflicts.\n",
    "Why Load Cleaned Data? Your SQLite databases (emotional_all_notna.sqlite, survival_analysis.sqlite) are perfect for this. Start your new analysis notebook by connecting to the relevant database and loading the specific tables (e.g., sa_60d_10p, medical_records_complete if needed for extra variables not in the SA tables).\n",
    "Why Primarily \"Ask\" Mode?\n",
    "Control: Analysis is iterative. You'll want to generate a plot, look at it, tweak it, run a model, check assumptions, modify it. \"Ask\" mode is better for these smaller, controlled steps and for debugging specific lines.\n",
    "Context: It works well within the existing code context of your notebook cell.\n",
    "Reliability: Generally more reliable for generating targeted code snippets or explaining existing ones.\n",
    "When to Consider Agentic (\"Generate\") Mode?\n",
    "Potentially useful for generating a first draft of a larger, self-contained analysis block in a new notebook if you have a very clear, detailed prompt (e.g., \"Using the dataframe sa_60d_10p, generate Python code with the lifelines library to: 1. Create a KaplanMeierFitter. 2. Fit the fitter using 'followup_period' as duration and '10pct_achieved' as event_observed. 3. Plot the overall survival curve. 4. Fit separate curves stratified by the 'sex' column. 5. Plot the stratified curves. 6. Perform a log-rank test comparing the curves stratified by 'sex'.\").\n",
    "Caveat: Be prepared to carefully review, debug, and potentially refactor the code generated by agentic mode. It might make assumptions or structure the code in a way you want to change.\n",
    "Additional Recommendations:\n",
    "\n",
    "Version Control (Git): Strongly consider using Git for your project directory. It allows you to track changes, revert if something breaks, and manage different analysis branches. Even working alone, it's invaluable.\n",
    "Save Intermediate Results: Continue saving key derived dataframes (like your survival analysis tables) to the SQLite database or separate files (.csv, .parquet). This makes reloading for specific tasks much faster.\n",
    "Modular Functions: Keep using functions for reusable analysis steps (e.g., a function to plot KM curves, a function to run and summarize a Cox model). This makes your analysis notebooks cleaner and easier to maintain.\n",
    "Start Simple: Begin with the core KM plots and univariate Cox models for your key eating behavior variables. Get those working and interpreted well before moving to complex multivariate models.\n",
    "In summary: you're in a great position. Leverage the cleaned data, start a fresh notebook for the survival analysis, primarily use \"Ask\" mode for iterative development, and be prepared for the human-intensive parts of interpretation and validation. Good luck!\n",
    "\n",
    "\n",
    "[7.50]\n",
    "- N day cutoff: datetime/NA\n",
    "- X % WL: number/NA\n",
    "\n",
    "can it be 1 table? or is that too chaotic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[8.10] this is the last question I wanted to ask copilot about which data frame structure is better for me: \n",
    "\n",
    "[**problems for future self**]\n",
    "Issue with the revised code: average calculations\n",
    "- averages are not calculated using a fixed time point, but the last measurement of everyone, which currently is defined by the achievement of target weight loss. So if someone has 10 measurements, but achieves target on the 7th, the last 3 measurements are excluded, and the 7th will be seen as the last one. However, this makes it look like the patient lost less weight than he actually did. \n",
    "- this made me think that maybe, additional columns should be included in the dataframe - like the first measurement, the first when target is achieved, and the last one. \n",
    "- this will create opportunities for better average calculations, logistic regression design, and whatnot, so it might be cool to add\n",
    "- but it will also create NA values, so I may want to use a fresher brain when thinking this through\n",
    "- below is the first ideation with AI about this\n",
    "- also, the new code does not contain number of measurements data!\n",
    "- [**and there is another problem:**] it would be important to do at least exploratory analyses \n",
    "    - we might be actually losing time by doing all this\n",
    "    - maybe a quick SA test run would help the efforts of seeing whether this is a right direction or not - tuesday is coming on!\n",
    "\n",
    "I'm thinking. I don't want to keep very different data in my dataset, this is very good for survival analysis looking at time-to-event - however, it is also interesting to see the exact weight lost at day X, the cutoff day.\n",
    "\n",
    "Would it be a good idea to include more results in the output datasets, that for the one part, can serve for accurate average calculations, and for the other, can be the basis of other types of analyses, like a logistic regression of having reached X days of followup, or X% weight loss on that followup length?\n",
    "\n",
    "Is this a good idea, to increase the complexity of this SQL, or should I actually create new tables, that contain different types of variables.\n",
    "\n",
    "\n",
    "GitHub Copilot\n",
    "Okay, let's break down this thought process. You're correctly identifying a nuance in survival analysis vs. fixed-timepoint analysis.\n",
    "\n",
    "Your Current Setup (Survival Focus):\n",
    "\n",
    "sa_... tables: Primarily designed for time-to-event.\n",
    "followup_period: Represents the time until the event (achieving X% weight loss) or the time until censoring (dropout or reaching the end of the observation window without success).\n",
    "weight_loss_pct: Represents the weight loss at the end_date, which corresponds to the event or censoring time.\n",
    "{target}%_achieved: Indicates if the event occurred within the observation period.\n",
    "Your New Requirement (Fixed-Timepoint Focus):\n",
    "\n",
    "You want to know the actual weight loss percentage specifically at the defined cutoff window (e.g., 60 +/- 10 days) for everyone who had a measurement within that window.\n",
    "This is useful for calculating accurate average weight loss at that specific time point and for other analyses like logistic regression (e.g., predicting target%_achieved based on baseline characteristics and the actual weight loss at day 60).\n",
    "Analysis & Recommendation:\n",
    "\n",
    "Is it a good idea? Yes, absolutely. Capturing the actual weight loss at the defined cutoff window provides valuable complementary information to the time-to-event data. It allows for different types of analysis and gives a clearer picture of the cohort's state at that specific time, regardless of when individuals might have hit the target before that window.\n",
    "\n",
    "Modify Existing Tables vs. Create New Tables?\n",
    "\n",
    "Argument for Modifying Existing Tables (sa_...):\n",
    "\n",
    "Cohesion: Keeps all information related to a specific analysis scenario (e.g., 10% target at 60 days) together in one place.\n",
    "Simplicity: Avoids doubling the number of tables in your database (9 -> 18).\n",
    "Direct Comparison: Makes it easy to compare the survival outcome (target%_achieved, followup_period) with the fixed-timepoint outcome (actual %WL at cutoff) for the same patients within the same table.\n",
    "Manageable Complexity: Adding a couple of columns is less complex to manage downstream than joining separate tables frequently.\n",
    "Argument for Creating New Tables (e.g., fixed_...):\n",
    "\n",
    "Purity: Keeps the sa_... tables strictly focused on survival metrics.\n",
    "Clarity: Might make the purpose of each table type slightly clearer initially.\n",
    "Recommendation: Modify the existing sa_... tables. The benefits of keeping related analysis data together and avoiding table proliferation outweigh the slight increase in table width. It aligns better with wanting to potentially use both types of information for related analyses (like your logistic regression idea).\n",
    "\n",
    "How to Implement (Conceptual):\n",
    "\n",
    "Inside your calculate_weight_loss_outcome function, after you've determined the baseline_row, measurements_within_window, and measurements_around_cutoff:\n",
    "\n",
    "Find the Measurement at Cutoff: Identify the last measurement that falls within the strict cutoff window (min_window_date to max_window_date). Let's call this cutoff_measurement_row.\n",
    "Calculate Actual WL% at Cutoff:\n",
    "If cutoff_measurement_row exists:\n",
    "Calculate actual_wl_pct_at_cutoff = ((baseline_weight - cutoff_measurement_row['weight_kg']) / baseline_weight) * 100\n",
    "Store cutoff_measurement_date = cutoff_measurement_row['measurement_date']\n",
    "If cutoff_measurement_row does not exist (patient dropped out before the window or had no measurement in the window):\n",
    "Set actual_wl_pct_at_cutoff = None (or NaN)\n",
    "Set cutoff_measurement_date = None (or NaT)\n",
    "Add to Results: Include actual_wl_pct_at_cutoff and cutoff_measurement_date in the result dictionary that gets appended to the results list.\n",
    "Code Snippet Idea (Inside calculate_weight_loss_outcome loop):\n",
    "\n",
    "Then, ensure these new columns are handled correctly when saving to the database in generate_survival_analysis_datasets.\n",
    "\n",
    "This approach gives you the best of both worlds within a single, manageable set of tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[19.10] was my daily progress really just revising where I was yesterday? \n",
    "- No, I actually did important code revisions, \n",
    "- identified important errors and gained a better understanding of my code\n",
    "- and probably, by the end of the day, got some nice ideas on how to best structure the dataframe, allowing for other analyses too!\n",
    "- i hope that today did good for the pipeline design, and that it will bear fruit\n",
    "\n",
    "[7.55] continuation of yesterday's SA debugging thread\n",
    "- days_to_final_measurement only counts BETWEEN days and not accounting for actual start and end date\n",
    "- incorrect dropout definition (only 0-days are considered for now)\n",
    "- target achievment % precision problems\n",
    "-> see all in the last cell from 16/4/25, correct the code accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**corrected, revised pseudocode for survival analysis input generation**]\n",
    "\n",
    "Define analysis parameters outside the functions\n",
    "\n",
    "weight_loss_targets = [10, 15]  # Weight loss target percentages to analyze\n",
    "time_windows = [60, 90, 120]    # Time windows in days to analyze\n",
    "window_span = 10               # Permissible span around target windows (+/- days)\n",
    "\n",
    "1 Data Loading\n",
    "FUNCTION load_measurements(connection):\n",
    "    Query all measurements\n",
    "    Convert dates to datetime\n",
    "    Return measurements dataframe\n",
    "\n",
    "FUNCTION load_medical_records(connection):\n",
    "    Query medical records data\n",
    "    Return medical records dataframe\n",
    "\n",
    "2 Data Preparation  \n",
    "FUNCTION prepare_patient_data(measurements, medical_records):\n",
    "    Identify earliest medical record for each patient\n",
    "    Filter measurements to only include measurements associated with the earliest medical record for each patient\n",
    "    For each patient:\n",
    "        Extract baseline data (first measurement)\n",
    "        Add demographic and behavior data from medical records\n",
    "    Return prepared patient dataframe\n",
    "\n",
    "3 Analysis Core\n",
    "FUNCTION calculate_weight_loss_outcome(patient_data, weight_loss_target, window_center, window_span):\n",
    "    Create empty results list\n",
    "    \n",
    "    For each patient:\n",
    "        Get baseline values\n",
    "        baseline_date = patient's first measurement date\n",
    "        baseline_weight = patient's first measurement weight\n",
    "        \n",
    "        Define time windows\n",
    "        min_window_date = baseline_date + (window_center - window_span) days\n",
    "        max_window_date = baseline_date + (window_center + window_span) days\n",
    "        \n",
    "        Check for measurements in window\n",
    "        measurements_within_window = get measurements between baseline and max_window_date\n",
    "        measurements_around_cutoff = get measurements between min_window_date and max_window_date\n",
    "        \n",
    "        Determine outcome based on survival analysis principles\n",
    "        IF no measurements after baseline:\n",
    "            Instant dropout\n",
    "            success = false\n",
    "            end_date = baseline_date\n",
    "            weight_loss = 0\n",
    "            dropout = true\n",
    "        ELSE:\n",
    "            Check if target achieved at any point\n",
    "            target_achieved = false\n",
    "            first_success_measurement = null\n",
    "            \n",
    "            FOR each measurement in measurements_within_window:\n",
    "                weight_loss = calculate percentage loss from baseline\n",
    "                IF ROUND(weight_loss, 2) >= weight_loss_target:\n",
    "                    target_achieved = true\n",
    "                    first_success_measurement = current measurement\n",
    "                    BREAK\n",
    "            \n",
    "            Determine final measurement using proper survival analysis principles\n",
    "            IF target_achieved:\n",
    "                Success case: use the measurement where target was first achieved\n",
    "                final_measurement = first_success_measurement\n",
    "                success = true\n",
    "                dropout = false\n",
    "            ELSE IF measurements_around_cutoff exist:\n",
    "                No success but followed through window: find measurement closest to center\n",
    "                target_date = baseline_date + window_center days\n",
    "                \n",
    "                Calculate distance to center for each measurement\n",
    "                FOR each measurement in measurements_around_cutoff:\n",
    "                    distance_to_center = abs(measurement_date - target_date)\n",
    "                \n",
    "                Find measurement with minimum distance to center\n",
    "                closest_measurement = measurement with minimum distance_to_center\n",
    "                final_measurement = closest_measurement\n",
    "                success = false\n",
    "                dropout = false\n",
    "            ELSE IF some followup exists but didn't reach window:\n",
    "                Delayed dropout: use the last available followup measurement\n",
    "                final_measurement = last measurement in measurements_within_window\n",
    "                success = false\n",
    "                dropout = true\n",
    "            \n",
    "            Calculate days properly (inclusive of both first and last date)\n",
    "            days_between = (final_measurement_date - baseline_date).days + 1\n",
    "            weight_loss = calculate percentage loss using final_measurement\n",
    "        \n",
    "        Add to results\n",
    "        Add patient outcome to results list\n",
    "    \n",
    "    Return results dataframe\n",
    "\n",
    "4 Main Workflow\n",
    "FUNCTION generate_survival_analysis_datasets(connection, weight_loss_targets, time_windows, window_span=10):\n",
    "    1 Load data once\n",
    "    measurements = load_measurements(connection)\n",
    "    medical_records = load_medical_records(connection)\n",
    "    \n",
    "    2 Prepare data once\n",
    "    prepared_data = prepare_patient_data(measurements, medical_records)\n",
    "    \n",
    "    3 Create results for each target/window combination\n",
    "    results = {}\n",
    "    summary = empty dataframe\n",
    "    \n",
    "    FOR each weight_loss_target in weight_loss_targets:\n",
    "        FOR each window in time_windows:\n",
    "            name = f\"sa_{window}d_{target}p\"\n",
    "            \n",
    "            Run the analysis\n",
    "            results[name] = calculate_weight_loss_outcome(\n",
    "                prepared_data, \n",
    "                weight_loss_target, \n",
    "                window, \n",
    "                window_span=window_span\n",
    "            )\n",
    "            \n",
    "            Add to summary\n",
    "            Add summary row with result stats\n",
    "    \n",
    "    4 Save results\n",
    "    Save results to database\n",
    "    \n",
    "    Return results, summary\n",
    "\n",
    "\n",
    "===VERY SIMPLY:===\n",
    "\n",
    "define analysis parameters\n",
    "load and prepare data\n",
    "    open measurements, open medical records, use only first medical record per patient\n",
    "analysis\n",
    "    get baseline measurements\n",
    "    define time windows and and measurement-window relationships\n",
    "    determine treatment outcome for survival analysis\n",
    "        check for instant dropout\n",
    "        else, check if target was achieved\n",
    "            determine final measurement\n",
    "                if target was achieved, take that measurement as final\n",
    "                elif there's a near-cutoff measurement, take that\n",
    "                elif, take the last measurement\n",
    "            calculate days passed and weight lost\n",
    "        update and reeturn resutls\n",
    "main\n",
    "    load and prepare data\n",
    "    create results for each target-window combination\n",
    "        name and run analyses\n",
    "        add to summary\n",
    "    return and save results and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**problems for future self:**] keep debugging SA data preparation. Find AI summary of progress, issues, proposals and next steps: \n",
    "\n",
    "Problems for Future Self: Survival Analysis Code Restructuring\n",
    "Core Issues Identified\n",
    "After reviewing the weight loss analysis code that creates survival analysis input files, we found several issues:\n",
    "\n",
    "- Single Responsibility Violation: The current function does too many things at once (data loading, processing, calculations)\n",
    "- Poor Separation of Concerns: Database operations are mixed with analysis logic\n",
    "- Redundant Calculations: Baseline BMI is extracted separately rather than during the main processing\n",
    "- Complex Conditional Logic: The nested if/else structure is difficult to follow\n",
    "- Inconsistent Dropout Definition: Only patients with zero follow-up are flagged as dropouts, but proper definition should include those who neither achieve target weight loss nor complete the follow-up period\n",
    "- Floating-Point Comparison Issues: Weight loss target achievement has precision problems (e.g., 14.87% accepted as 15% but 14.61% not)\n",
    "\n",
    "Original Code Structure (Pseudocode)\n",
    "\n",
    "FUNCTION analyze_weight_loss(database_connection, weight_loss_target, time_window_center, time_window_span):\n",
    "\n",
    "    1. Query all measurements from database\n",
    "    2. Query medical record data from database\n",
    "    3. Convert dates to datetime format\n",
    "    \n",
    "    4. Filter to only include earliest medical record for each patient\n",
    "    \n",
    "    5. Extract baseline BMI separately by:\n",
    "       - Group by patient\n",
    "       - Take first record for each patient\n",
    "       - Create new dataframe with just patient_id and BMI\n",
    "    \n",
    "    6. For each (patient, medical_record) group:\n",
    "       a. Get baseline measurement (first measurement date and weight)\n",
    "       b. Calculate time window boundaries (center ± span)\n",
    "       c. Find all measurements between baseline and window end\n",
    "       d. Initialize variables (end_date, final_weight, etc.)\n",
    "       \n",
    "       e. IF patient has no measurements after baseline:\n",
    "          - Set end_date = baseline_date (zero follow-up)\n",
    "          - Mark as dropout\n",
    "       ELSE:\n",
    "          - Check all measurements to see if target weight loss is achieved\n",
    "          - Find measurement in target window (or closest to it)\n",
    "          - Calculate weight loss percentage\n",
    "          - Update variables\n",
    "          \n",
    "       f. Add this patient's data to results list\n",
    "    \n",
    "    7. Convert results list to DataFrame\n",
    "    8. Merge with medical records data\n",
    "    9. Merge with baseline BMI data\n",
    "    \n",
    "    10. Return final dataframe\n",
    "\n",
    "Improved Code Structure (Pseudocode)\n",
    "\n",
    "1. Data Loading\n",
    "FUNCTION load_measurements(connection):\n",
    "    Query all measurements\n",
    "    Convert dates to datetime\n",
    "    Return measurements dataframe\n",
    "\n",
    "FUNCTION load_medical_records(connection):\n",
    "    Query medical records data\n",
    "    Return medical records dataframe\n",
    "\n",
    "2. Data Preparation  \n",
    "FUNCTION prepare_patient_data(measurements, medical_records):\n",
    "    Identify earliest medical record for each patient\n",
    "    Filter measurements to only include those medical records\n",
    "    For each patient:\n",
    "        Extract baseline data (first measurement)\n",
    "        Add demographic and behavior data from medical records\n",
    "    Return prepared patient dataframe\n",
    "\n",
    "3. Analysis Core\n",
    "FUNCTION calculate_weight_loss_outcome(patient_data, weight_loss_target, window_center, window_span):\n",
    "    Create empty results list\n",
    "    \n",
    "    For each patient:\n",
    "        Get baseline values\n",
    "        baseline_date = patient's first measurement date\n",
    "        baseline_weight = patient's first measurement weight\n",
    "        \n",
    "        Define time windows\n",
    "        min_window_date = baseline_date + (window_center - window_span) days\n",
    "        max_window_date = baseline_date + (window_center + window_span) days\n",
    "        \n",
    "        Check for measurements in window\n",
    "        measurements_within_window = get measurements between baseline and max_window_date\n",
    "        measurements_around_cutoff = get measurements between min_window_date and max_window_date\n",
    "        \n",
    "        Determine outcome based on survival analysis principles\n",
    "        IF no measurements after baseline:\n",
    "            Instant dropout\n",
    "            success = false\n",
    "            end_date = baseline_date\n",
    "            weight_loss = 0\n",
    "            dropout = true\n",
    "        ELSE:\n",
    "            Check if target achieved at any point\n",
    "            target_achieved = false\n",
    "            first_success_measurement = null\n",
    "            \n",
    "            FOR each measurement in measurements_within_window:\n",
    "                weight_loss = calculate percentage loss from baseline\n",
    "                IF ROUND(weight_loss, 2) >= weight_loss_target:\n",
    "                    target_achieved = true\n",
    "                    first_success_measurement = current measurement\n",
    "                    BREAK\n",
    "            \n",
    "            Determine final measurement using proper survival analysis principles\n",
    "            IF target_achieved:\n",
    "                # Success case: use the measurement where target was first achieved\n",
    "                final_measurement = first_success_measurement\n",
    "                success = true\n",
    "                dropout = false\n",
    "            ELSE IF measurements_around_cutoff exist:\n",
    "                # No success but followed through window: use measurement closest to center\n",
    "                final_measurement = measurement CLOSEST TO window_center in measurements_around_cutoff\n",
    "                success = false\n",
    "                dropout = false\n",
    "            ELSE IF some followup exists but didn't reach window:\n",
    "                # Delayed dropout: use the last available followup measurement\n",
    "                final_measurement = last measurement in measurements_within_window\n",
    "                success = false\n",
    "                dropout = true\n",
    "            \n",
    "            Calculate days properly (inclusive of both first and last date)\n",
    "            days_between = (final_measurement_date - baseline_date).days + 1\n",
    "            weight_loss = calculate percentage loss using final_measurement\n",
    "            \n",
    "            Determine if patient is a dropout (revised definition)\n",
    "            dropout = (NOT success) AND (days_between < (window_center - window_span))\n",
    "        \n",
    "        Add to results\n",
    "        Add patient outcome to results list\n",
    "    \n",
    "    Return results dataframe\n",
    "\n",
    "4. Main Workflow\n",
    "FUNCTION generate_survival_analysis_datasets(connection, weight_loss_targets, time_windows):\n",
    "    1. Load data once\n",
    "    measurements = load_measurements(connection)\n",
    "    medical_records = load_medical_records(connection)\n",
    "    \n",
    "    2. Prepare data once\n",
    "    prepared_data = prepare_patient_data(measurements, medical_records)\n",
    "    \n",
    "     3. Create results for each target/window combination\n",
    "    results = {}\n",
    "    summary = empty dataframe\n",
    "    \n",
    "    FOR each weight_loss_target in weight_loss_targets:\n",
    "        FOR each window in time_windows:\n",
    "            name = f\"sa_{window}d_{target}p\"\n",
    "            \n",
    "            Run the analysis\n",
    "            results[name] = calculate_weight_loss_outcome(\n",
    "                prepared_data, \n",
    "                weight_loss_target, \n",
    "                window, \n",
    "                window_span=10\n",
    "            )\n",
    "            \n",
    "            Add to summary\n",
    "            Add summary row with result stats\n",
    "    \n",
    "    4. Save results\n",
    "    Save results to database\n",
    "    \n",
    "    Return results, summary\n",
    "    \n",
    "Progress Made & Next Steps\n",
    "You've made excellent progress today! You've:\n",
    "\n",
    "- Identified key issues in the survival analysis codebase\n",
    "- Designed a much cleaner architecture with proper separation of concerns\n",
    "- Improved the dropout definition for more accurate analysis\n",
    "- Fixed the precision issues with weight loss calculations\n",
    "\n",
    "Tomorrow, you'll be ready to implement these improvements and have a much more reliable and maintainable codebase. You're very close to being able to run robust survival analyses that will reveal meaningful patterns in your weight loss data.\n",
    "\n",
    "The restructured code will make it easier to extend your analysis (e.g., adding new predictors or trying different time windows) and will produce more trustworthy results. You're setting yourself up for success with the actual statistical modeling in your next steps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[15.30] continuing\n",
    "\n",
    "[11.10 **problems for future self:**]\n",
    "- revise and comment the modules that complete medical records, and create the survival analysis input\n",
    "- hunt down the issues noted at 9.05 \n",
    "\n",
    "[9.05] issues:  \n",
    "- *medical records complete is smaller than original medical records, look into it - SOLVED - data is lost because any medical record with no measurement associated to it is dropped*\n",
    "- *measurements_with_metadata probably has irrelevant columns at the end - SOLVED - actually, that data can be relevant in better identifying the relationship of a given measurement to the prescription it was linked to, so it is kept with naming updates*\n",
    "- dropout handling: only those with 0 days of followup are considered dropouts, while dropout should be someone who does not achieve nor success nor target measurement time SA INPUT DF\n",
    "- 14% WL as True for 15% SA INPUT DF\n",
    "- column order, bmi localization, table order in SQL in the survival analysis\n",
    "\n",
    "\n",
    "\n",
    "[8.05] commit message: \n",
    "\n",
    "Updated the way that the Paper 1-specific SQL is created. After subsetting the medical_records table, all other tables were subsetted by patient_id only. Prescriptions however contained medical records from some patients that were lacking emotional data. \n",
    "\n",
    "The updated code is supposed to filter prescriptions by both patient and medical record IDs, really only keeping records with complete emotional data availability. \n",
    "\n",
    "\n",
    "number of prescriptions when using the old code, that filters prescriptions by patient ID only: 16937\n",
    "number when using the new code that filters both by patient and medical record IDs: 10190\n",
    "\n",
    "started at 7.40 today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**problems for future self:**] 18% of medical record-derived data in the lates SA input tables is missing. That means that the medical records for those patients are not available, and that there is no consistency regarding the records contained in the study-specific SQL. That probably makes me have to look several steps back - in the future! [*problem solved on 16/4/2025 - the SQL subsetting was done incorrectly, prescriptions were filtered by patient ID and not medical record ID, and so in the step of linking prescriptions to measurements, many measurements that had no corresponding emotional values were retained*]\n",
    "\n",
    "[19.46] yay, survival analysis input done! But there are issues - it all needs to be revised, all the pipeline for this paper-specific analysis\n",
    "\n",
    "[16.30] prompt to get survival analysis input\n",
    "\n",
    "Write a module that pulls data from measurements_with_metadata, and obtains input data organized for survival analysis. The outcome of interest is 10% weight loss. \n",
    "\n",
    "The code should group the measurements (rows) by patient id and medical record ID (measurements from the same treatment of the same patient), and take the first measurement of each group as the reference baseline measurement. \n",
    "Counting from the first measurement, it should look at the following measurements in a range of 60, +/- 10 days, \n",
    "and check the porcentual amount of weight lost in each timepoint. \n",
    "If a weight loss over 10% is achieved, the days it took to achieve it should be noted. \n",
    "If the patient did not follow the treatment for at least 60 +/- 10 days, the last measurement should be noted.\n",
    "\n",
    "The output should be a data frame called sa_60d_10%. It should have the following columns: \n",
    "- patient_id - text, patient ID\n",
    "- medical_record_id - text, medical record ID\n",
    "- first_measurement_date - datetime, the first measurement in the group\n",
    "- end_measurement_date - datetime, either the last measurement in the group (in case of dropout before 60 days, OR not achieving 10% weight loss in 60 days) OR the first measurement where 10% weight loss is achieved\n",
    "- days_to_end_measurement - numeric, days passed between the first and last measurement date\n",
    "- nr_measurements - numeric, the number of measurements between the first and the end measurement\n",
    "- baseline_weight - numeric, the weight at time of the first measurement\n",
    "- final_weight - numeric, the weight at the time of the last measurement\n",
    "- wl% - numeric, the porcentual difference between the baseline and final weight values\n",
    "- 10%_achieved - bool, yes/no, yes if final weight is over 10% less than baseline, no if not\n",
    "- dropout - bool, yes/no, yes if didn't reach 60+/- 10 days of followup AND didn't reach over 10% weight loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[13.15] **reu Alfredo** \n",
    "- 6 regresiones para 6 variables, y luego uno para todo\n",
    "- pérdida de peso a los 50, 60, 70 días, y 7.5, 10, 12.5% por ejemplo\n",
    "- hipótesis para JPM: personalizar pronóstico de adelgazamiento según estado emocional basal\n",
    "- apoyo estadístico: 50€ por hora y media, 1-2 veces al mes. Vendría a través de ISCYL, en bonos, probable que para mí, y lo a Árpi\n",
    "- no abusar de chatgpt! comprobar siempre las propuestas. \n",
    "\n",
    "\n",
    "[12.25] haladunk, egyre több metadata egyre koncentráltabban van jelen a bázisban. kövi nagy lépés a 10% eventek időpontjának megállapítása. utána illeszthetőek a regressziós modellek. nem hiszem, h ez ma meglesz, ezzel együtt haladunk ahogy kell. \n",
    "\n",
    "[7.40] Mára miket kéne csinálni? \n",
    "- exploratory association plot with 60-day deltas and emotional scores; picking first records from multirec patients\n",
    "- possibly: making a **larger wide df**, that contains the most data possible from patients\n",
    "- regarding survival analysis: \n",
    "    - define input data and its structure\n",
    "    - exclude inmediate dropouts\n",
    "    - EDA: descriptive stats and recommended KM curves\n",
    "    - advanced models: \n",
    "        - define train/test sets\n",
    "        - fit simple Cox model, 1 or a few variables\n",
    "        - fit competing risk models with time strata (because of proportional hazards assumption, although maybe that is for Cox actually?)\n",
    "        - maybe fit parametric models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[AI GENERATED ANALYSIS PROTOCOL BASED ON DISCUSSIONS THROUGHOUT THE DAY]\n",
    "\n",
    "**Analysis Protocol: Emotional Behaviors and Weight Loss Success**  \n",
    "**Objective**: Understand how baseline emotional/eating behaviors predict the time it takes to achieve 10% weight loss, while addressing dropouts and statistical pitfalls.\n",
    "\n",
    "**1. Data Preparation**  \n",
    "**Goal**: Clean and structure your data for survival analysis.  \n",
    "- **Define Events**:  \n",
    "  - **Success**: The day a participant first reaches ≥10% weight loss (e.g., Day 45).  \n",
    "  - **Censoring**: The last day a participant was measured if they dropped out or never reached 10% loss.  \n",
    "- **Exclude Immediate Dropouts**:  \n",
    "  - **Why?** Participants with only 1 measurement (e.g., Day 0) provide no information about *time-to-event*. Including them would artificially inflate the number of \"censored\" cases without meaningful follow-up.  \n",
    "  - **How?** Remove anyone with only baseline data (no follow-up).  \n",
    "\n",
    " **2. Exploratory Analysis**  \n",
    "**Goal**: Understand patterns in your data before modeling.  \n",
    "- **Descriptive Stats**:  \n",
    "  - Report averages for continuous variables (e.g., \"Average emotional eating score: 6.2/10\").  \n",
    "  - Report percentages for categorical variables (e.g., \"60% female\").  \n",
    "- **Kaplan-Meier Curves**:  \n",
    "  - **What?** A graph showing the probability of *not* achieving 10% weight loss over time.  \n",
    "  - **How?** Compare groups (e.g., high vs. low emotional eating). If the curves separate, the variable might matter.  \n",
    "\n",
    "**3. Primary Analysis: Cox Regression**  \n",
    "**Goal**: Test if emotional behaviors predict *how quickly* people lose weight.  \n",
    "- **Model 1 (Simple)**:  \n",
    "  - Predictor: One emotional variable (e.g., emotional eating score).  \n",
    "  - Output: **Hazard ratio (HR)**.  \n",
    "    - HR > 1: Faster weight loss.  \n",
    "    - HR  0.5**: Model is better than random guessing.  \n",
    "\n",
    "**5. Sensitivity Analyses**  \n",
    "**Goal**: Check if results hold under different assumptions.  \n",
    "- **Competing Risks**:  \n",
    "  - **What?** Treat dropout as a competing event (e.g., someone quits and can’t lose weight).  \n",
    "  - **How?** Use Fine-Gray models instead of Cox.  \n",
    "- **Parametric Models**:  \n",
    "  - **What?** Assume the risk of weight loss decreases over time (e.g., Weibull model).  \n",
    "  - **Why?** Compare results to Cox for consistency.  \n",
    "\n",
    "**6. Reporting Results**  \n",
    "**Tables**:  \n",
    "- Show hazard ratios (HRs), 95% confidence intervals (CIs), and *p*-values for all models.  \n",
    "**Figures**:  \n",
    "- Kaplan-Meier curves for key predictors.  \n",
    "- Forest plots comparing HRs across subgroups.  \n",
    "\n",
    "**Key Questions to Answer**  \n",
    "1. Does emotional eating slow down or speed up weight loss?  \n",
    "2. Do effects change over time (e.g., matter more in the first month)?  \n",
    "3. Are results robust after adjusting for age, sex, and BMI?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[jotting down paper notes taken over the day] Egyértelmű, h cikkre kell fókuszálni, az is, h ehhez a Cox reg fontos concept. Ott kell felvenni a fonalat, ahol letettem - mérések és metaadatok linkelése. Ha azt jól csináltam, ott meg is vannak a 60 napos delták - igaz még az input adatokat tisztítani kell, pl duplikáltak kidobása stb, visszamenőleg tisztítani kell a pipelinet. Illetve, ezek tentatív elemzések és nem végleges adatok lesznek, egészen addig amíg a Measurements átnézése meg nem történik. \n",
    "\n",
    "[JOTS ON COX/SURVIVAL ANALYSIS RESEARCH] \n",
    "- Cox model: effect of a unit increase in a covariate: multiplicative\n",
    "- low risk vs high risk / low/high emotionality\n",
    "- hazard ratio: the key concept, that's estimated in a Cox model. Associated with a risk factor or predictor for a given endpoint - meaning? Its prerequisite is assesment of proportional hazards. Meaning? \n",
    "- Kaplan-Meier: simplest SA, after comes Cox, penalized Cox models like ridge, lasso, elastic net, and more robust MLs for SA\n",
    "- SA: effects of several factors on an event happening - rate of this event happening is the HAZARDS RATE; risk of event X at time t\n",
    "- want to find out the influence of factors A, B, C, D, X, Y, Z on the RATE OF THE EVENT HAPPENING? \n",
    "- covariates: predictor variables, factors\n",
    "- linking COVARIATES data to TIME OF EVENT data - establish LINKS with SA\n",
    "- selecting best predictive variable is important    \n",
    "- concordance index: correlation between predicted risk scores and time point\n",
    "- Cox model needs train/test data too!\n",
    "- Penalized models, Random survival forest, survival SMVs, survival GB can have interesting advantages, \n",
    "- scikit-survival: https://scikit-survival.readthedocs.io/en/stable/user_guide/index.html\n",
    "\n",
    "[BRAINSTORM: HOW TO USE IT]\n",
    "- this is like a regression - but parts of the training data is CENSORED due to dropout, death, and in some cases, the outcome is just not achieved - > we can use data from ALL patients and fitting and adequate survival model we can account for dropouts\n",
    "- existing conditions, comorbidities as confounders should also be accounted for; and a subset with genetics, also maybe look for links in weight gain reasons\n",
    "- observe 60 days - some drop out, some lose 10%, some don't\n",
    "- adjust for age, sex, baseline BMI, comorbidities etc\n",
    "- Still, SA focuses on **time to event happening**, which may not be the most revealing test to look for associations between emotional eating and WL outcomes. \n",
    "- clause 0, if your supervisor asks you to look into something, you do\n",
    "- clause 1, survival analysis looks good for the case where we have dropouts, successes, different durations till success, no success and all\n",
    "- what can be complicated is the relatively large nr of covariates in our analyses. we need to adjust for demographics, anthropometrics, emotional and clinical variables. maybe more complex models are the answer here. scikit-surv guide mentions versatility of SSVMs for example. Perplexity recommends those for complex, highD, nonlinear datasets. \n",
    "- what we *really care about* is not the time to success, but the *influence of certain covariates on success*. \n",
    "- **competing risk models**, like Fine-Gray, accounts for meaningful dropouts - like, if emotional values influence on dropout, then dropout should be accounted for as a competing risk that prevents the outcome of interest. If a covariate predicts higher risk for a competing risk, that is insightful. Otherwise, non-informative dropouts should be censored, and the researcher should stick to a normal Cox model. \n",
    "- regarding the analysis: time-to-event analysis should be the best, like identifying the time needed to achieve a 10% WL. OK, that implies doing the absolute to relative calculation maybe more times, but I think that can be a dynamic part of the code, no need to calculate for every measurement, only pulling a function on measurements of interest. \n",
    "- IMPORTANT: Proportional hazards is some kind of assumption in Cox, that the effect size of one covariate is constant over time, does not change. Like if hunger influences weight this much at baseline, the size of the influence will stay constant. **This is risky** and needs to be adjusted for - emotional values can change, and their effects can change. Some kind of test needs to be ran to check whether this assumption is violated (Schoenfeld residuals, 'check_assumptions' in scikit-survival), and if it is, stratifying the data for periodic blocks and doing different analyses for each block can be a way to go. Like, fit a new model for every 20 days, and engineer it well enough to link the different ones. In every model, the covariates are baseline (cross-sectional basically), the outcome is derived from the measurements that are continuously recorded. The goal is to see how the weight decreases, in function of some variables, and how long it takes to reach 5, 10, 15, 20% WL. \n",
    "\n",
    "[QUESTIONS]\n",
    "- what should the input data structure look like for the survival models? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**problems for future self**] még mindig messy a notebook, ezt a pipelinet nem is látom át egészen, és duplikált mérések vannak az inputban, mert colclean, nem rowclean inputtal fut le a kód\n",
    "\n",
    "[09.11] Csökkenni fog a hosszútávú adatokkal rendelkező páciensek száma az érzelmi datasetben, ha 60 nap followupra szűrünk, többen dropoutoltak. Viszont a baseline adatokban az érzelem - baseline obesity és a droput rate közötti összefüggéseket is meg lehet nézni\n",
    "\n",
    "makin progress! két jó ötlet, és megvan a 2 df a 60day delta weight értékekkel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4/4/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[16.25]\n",
    "Szeretnék mock analíziseket csinálni, amelyekben összehasonlítom az eating behavior és a weight loss outcome adatokat. Mivel egy ember több kezelésen megy át, és a kezelések hossza változó, a tudományos pontosság miatt fontos, hogy fix vagy nagyjából fix időtartamú kezeléseket nézzünk (persze később teljes kezelésre is rá lehet vetíteni, 60-day weight loss vs overall treatment outcome). \n",
    "\n",
    "Ahhoz, hogy a fix időtartamú követési időszakok első és utolsó mérési adatát megszerezzük, ahhoz minden méréshez hozzá kell rendelni a hozzá tartozó kezelést, illetve receptet, amiből megtudjuk, hogy a kezelés melyik szakaszában van a páciens, és hogy az adott szakasz meddig tartott, illetve hogy maga az egész kezelés milyen hosszú volt. Most ami megvan, azt hiszem, hogy a kezelések és receptek hozzá vannak rendelve az egyes mérésekhez. \n",
    "\n",
    "Ezek a hozzárendelések long formájúak, és tovább vannak fejlesztve egy olyan táblázatban, ahol minden prescription, step és medical record első és utolsó mérése van, illetve a köztük eltelt idő és súlyváltozás. Ez egyfajta megközelítés, olvashatóbb, viszont elvesznek a köztes adatok. Idáig jutottam, és itt megakadtam egy kicsit, hogy akkor most hogy is tovább? Nem is vagyok biztos benne, hogy egyáltalán látom a problémát, ami megakasztott. \n",
    "\n",
    "Amit szeretnék, az 1 treatment cikluson belüli, 1 medical recordhoz tartozó 2 hónap körüli mérések súlyváltozása. Az kulcsfontosságú, hogy egy medical recordhoz tartozzanak, az viszont, hogy melyik lépéshez tartoznak, az inkább kiegészítő információ. Sok kontextust ad, mert tudjuk, hogy keto vagy nem keto fázisban van-e a páciens, de nem végzetes hiba, ha ez az infó elvész. Ami végzetes hiba lenne, az pl. két kezelési ciklus adatainak az összevonása. \n",
    "\n",
    "Tehát a most meglévő megközelítéssel, a prescription/step/record szinten is első és utolsó adatot tartalmazó táblával az a baj, hogy túl bonyolult, és talán adatot is veszítek. Elég lenne egy olyan tábla, ahol 1 medical recordhoz tartozó adatok vannak, baseline és 3, +/- 1 hónap cutoffnál. Tehát a most (piszkozat állapotban) 'linked' nevű táblázat sorait kéne patient>medical record szerint csoportosítani, measurement_date szerint rendezni, és az első méréstől számított 2-4 hónap közötti, 3-hoz legközelebbi értéket kinyerni, ezzel számolni egy pivoted delta weight táblázatot, amiben benne van a step is, mint metadata. Ezeket a súlyadatokat lehet már korreláltatni az érzelmi adatokkal, és a megfelelő metadata ismeretében könnyebb a cleaning és az értelmezés is. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
